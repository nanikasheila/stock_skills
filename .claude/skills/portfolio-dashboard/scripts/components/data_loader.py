"""ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ â€” ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼.

æ—¢å­˜ã® portfolio_manager / history_store / yahoo_client ã‚’æ´»ç”¨ã—ã¦
ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚

å–å¼•å±¥æ­´ï¼ˆJSON/CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰ã‹ã‚‰å„æ—¥ã®ä¿æœ‰çŠ¶æ³ã‚’å¾©å…ƒã—ã€
æ ªä¾¡å±¥æ­´ã¨æ›ã‘åˆã‚ã›ã¦è³‡ç”£æ¨ç§»ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
"""

from __future__ import annotations

import sys
import os
import time as _time
from collections import defaultdict
from datetime import datetime, timedelta, date
from pathlib import Path
from typing import Optional

import pandas as pd

# --- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ sys.path ã«è¿½åŠ  ---
_PROJECT_ROOT = str(Path(__file__).resolve().parents[5])
if _PROJECT_ROOT not in sys.path:
    sys.path.insert(0, _PROJECT_ROOT)

_DEFAULT_HISTORY_DIR = str(Path(_PROJECT_ROOT) / "data" / "history")
_PRICE_CACHE_DIR = Path(_PROJECT_ROOT) / "data" / "cache" / "price_history"
_CACHE_TTL_SECONDS = 4 * 3600  # 4 hours

from src.core.portfolio.portfolio_manager import (
    load_portfolio,
    get_fx_rates,
    DEFAULT_CSV_PATH,
)
from src.core.models import Position
from src.core.common import is_cash
from src.core.ticker_utils import infer_currency
from src.data import yahoo_client
from src.data.history_store import load_history
from src.core.health_check import (
    check_trend_health,
    check_change_quality,
    check_long_term_suitability,
    compute_alert_level,
    ALERT_NONE,
    ALERT_EARLY_WARNING,
    ALERT_CAUTION,
    ALERT_EXIT,
)
from src.core.screening.indicators import (
    calculate_shareholder_return,
    calculate_shareholder_return_history,
    assess_return_stability,
)
from src.core.value_trap import detect_value_trap


# ---------------------------------------------------------------------------
# 1. ç¾åœ¨ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼ˆéŠ˜æŸ„åˆ¥è©•ä¾¡é¡ï¼‰
# ---------------------------------------------------------------------------

def get_current_snapshot(
    csv_path: str = DEFAULT_CSV_PATH,
) -> dict:
    """ç¾åœ¨ã®ä¿æœ‰éŠ˜æŸ„ã”ã¨ã®è©•ä¾¡é¡ã‚’å–å¾—ã—ã¦ dict ã§è¿”ã™.

    Returns
    -------
    dict
        positions: list[dict]  å„éŠ˜æŸ„
        total_value_jpy: float
        fx_rates: dict
        as_of: str
    """
    positions = load_portfolio(csv_path)
    fx_rates = get_fx_rates(yahoo_client)

    result_positions: list[dict] = []
    total_value_jpy = 0.0

    for pos in positions:
        symbol = pos["symbol"]
        shares = pos["shares"]
        cost_price = pos["cost_price"]
        cost_currency = pos["cost_currency"]
        memo = pos.get("memo", "")
        purchase_date = pos.get("purchase_date", "")

        if is_cash(symbol):
            currency = symbol.replace(".CASH", "")
            rate = fx_rates.get(currency, 1.0)
            eval_jpy = shares * cost_price * rate
            result_positions.append({
                "symbol": symbol,
                "name": memo or symbol,
                "shares": shares,
                "current_price": cost_price,
                "currency": currency,
                "evaluation_jpy": eval_jpy,
                "cost_jpy": eval_jpy,  # Cash: æç›Šã‚¼ãƒ­
                "pnl_jpy": 0,
                "pnl_pct": 0,
                "sector": "Cash",
            })
            total_value_jpy += eval_jpy
            continue

        info = yahoo_client.get_stock_info(symbol)
        if not info:
            continue

        price = info.get("price", 0) or 0
        currency = info.get("currency") or infer_currency(symbol)
        rate = fx_rates.get(currency, 1.0)
        eval_jpy = shares * price * rate
        cost_rate = fx_rates.get(cost_currency, 1.0)
        cost_jpy = shares * cost_price * cost_rate

        result_positions.append({
            "symbol": symbol,
            "name": info.get("name", memo or symbol),
            "shares": shares,
            "current_price": price,
            "currency": currency,
            "evaluation_jpy": eval_jpy,
            "cost_jpy": cost_jpy,
            "pnl_jpy": eval_jpy - cost_jpy,
            "pnl_pct": ((eval_jpy / cost_jpy) - 1) * 100 if cost_jpy else 0,
            "sector": info.get("sector", ""),
            "purchase_date": purchase_date,
        })
        total_value_jpy += eval_jpy

    # å®Ÿç¾æç›Šã®è¨ˆç®—
    trades = _build_holdings_timeline()
    realized = _compute_realized_pnl(trades, fx_rates)

    return {
        "positions": result_positions,
        "total_value_jpy": total_value_jpy,
        "fx_rates": fx_rates,
        "realized_pnl": realized,
        "as_of": datetime.now().isoformat(timespec="seconds"),
    }


# ---------------------------------------------------------------------------
# 2. å£²è²·å±¥æ­´ã‹ã‚‰æ™‚ç³»åˆ—ã®ä¿æœ‰çŠ¶æ³ã‚’å¾©å…ƒ
# ---------------------------------------------------------------------------

def _build_holdings_timeline(
    base_dir: Optional[str] = None,
) -> list[dict]:
    """trade å±¥æ­´ã‚’æ—¥æ™‚é †ã«ãƒ­ãƒ¼ãƒ‰ã—ã¦è¿”ã™."""
    trades = load_history("trade", base_dir=base_dir or _DEFAULT_HISTORY_DIR)
    # å–å¼•æ—¥ (date) ã§ã‚½ãƒ¼ãƒˆã€‚åŒä¸€æ—¥ã¯ buy/transfer â†’ sell ã®é †ã«ä¸¦ã¹ã‚‹
    _TRADE_TYPE_ORDER = {"transfer": 0, "buy": 1, "sell": 2}
    trades.sort(key=lambda t: (
        t.get("date", ""),
        _TRADE_TYPE_ORDER.get(t.get("trade_type", "buy"), 1),
    ))
    return trades


def _reconstruct_daily_holdings(
    trades: list[dict],
) -> dict[str, dict[str, int]]:
    """å„å–å¼•æ—¥æ™‚ç‚¹ã§ã®å…¨éŠ˜æŸ„ä¿æœ‰æ ªæ•°ãƒãƒƒãƒ—ã‚’è¿”ã™.

    buy / transfer â†’ ä¿æœ‰è¿½åŠ ã€sell â†’ ä¿æœ‰å‰Šæ¸›ã€‚

    Returns
    -------
    dict
        date_str -> { symbol -> cumulative_shares }
    """
    cumulative: dict[str, int] = {}
    daily_snapshots: dict[str, dict[str, int]] = {}

    for trade in trades:
        symbol = trade["symbol"]
        shares = trade.get("shares", 0)
        trade_type = trade.get("trade_type", "buy")
        date_str = trade.get("date", "")

        if trade_type in ("buy", "transfer"):
            cumulative[symbol] = cumulative.get(symbol, 0) + shares
        elif trade_type == "sell":
            cumulative[symbol] = max(0, cumulative.get(symbol, 0) - shares)
            if cumulative[symbol] == 0:
                del cumulative[symbol]

        daily_snapshots[date_str] = dict(cumulative)

    return daily_snapshots


def _compute_invested_capital(
    trades: list[dict],
    fx_rates: dict[str, float],
) -> dict[str, float]:
    """ç´¯ç©æŠ•è³‡é¡(å††æ›ç®—)ã®æ¨ç§»ã‚’è¿”ã™.

    buy/transfer â†’ +æŠ•è³‡é¡ã€sell â†’ âˆ’å£²å´é¡
    å—æ¸¡é‡‘é¡ã§ã¯ãªã shares*price*fx_rate ã§è¨ˆç®—ã€‚

    Returns
    -------
    dict
        date_str -> cumulative_invested_jpy
    """
    cumulative = 0.0
    invested: dict[str, float] = {}

    for trade in trades:
        shares = trade.get("shares", 0)
        price = trade.get("price", 0)
        currency = trade.get("currency", "JPY")
        trade_type = trade.get("trade_type", "buy")
        date_str = trade.get("date", "")
        rate = fx_rates.get(currency, 1.0)
        amount_jpy = shares * price * rate

        if trade_type in ("buy", "transfer"):
            cumulative += amount_jpy
        elif trade_type == "sell":
            cumulative -= amount_jpy
        cumulative = max(0.0, cumulative)

        invested[date_str] = cumulative

    return invested


def _trade_cost_jpy(
    trade: dict,
    global_fx_rates: dict[str, float],
) -> float:
    """å–å¼•ã®ç´„å®šé‡‘é¡ã‚’JPYã§è¨ˆç®—ã™ã‚‹.

    å„ªå…ˆé †ä½:
    1. settlement_jpy + settlement_usd * fx_rate (ä¸¡æ–¹ã‚ã‚‹å ´åˆ)
    2. settlement_jpy ãŒæ­£ â†’ ãã®ã¾ã¾ä½¿ç”¨
    3. settlement_usd * fx_rate (å–å¼•æ—¥ãƒ¬ãƒ¼ãƒˆ)
    4. shares * price * fx_rate (å–å¼•æ—¥ãƒ¬ãƒ¼ãƒˆã§è¨ˆç®—)
    5. shares * price * ç¾åœ¨ã®FXãƒ¬ãƒ¼ãƒˆ (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
    """
    sjpy = trade.get("settlement_jpy", 0) or 0
    susd = trade.get("settlement_usd", 0) or 0
    fx = trade.get("fx_rate", 0) or 0

    if sjpy > 0 and susd > 0:
        # Mixed settlement (JPY + USD portions)
        return sjpy + susd * fx
    elif sjpy > 0:
        return sjpy
    elif susd > 0 and fx > 0:
        return susd * fx
    elif fx > 0:
        # FX rate available but no explicit settlement â†’ use price * fx_rate
        shares = trade.get("shares", 0)
        price = trade.get("price", 0)
        return shares * price * fx
    else:
        # Final fallback: use current FX rate
        shares = trade.get("shares", 0)
        price = trade.get("price", 0)
        cur = trade.get("currency", "JPY")
        rate = global_fx_rates.get(cur, 1.0)
        return shares * price * rate


def _compute_realized_pnl(
    trades: list[dict],
    fx_rates: dict[str, float],
) -> dict:
    """FIFOæ–¹å¼ã§å®Ÿç¾æç›Šã‚’è¨ˆç®—ã™ã‚‹ï¼ˆç‚ºæ›¿æ›ç®—ãƒ»æ ªå¼åˆ†å‰²å¯¾å¿œç‰ˆï¼‰.

    æ”¹å–„ç‚¹:
    - ç‚ºæ›¿æ›ç®—: CSVã®å—æ¸¡é‡‘é¡/ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ã„ã€å–å¼•æ™‚ç‚¹ã®JPYæ›ç®—ã§æç›Šã‚’ç®—å‡º
    - æ ªå¼åˆ†å‰²: transfer(å…¥åº«)ã§price=0ã®å ´åˆã€æ—¢å­˜ãƒ­ãƒƒãƒˆã®å˜ä¾¡ã‚’åˆ†å‰²æ¯”ç‡ã§èª¿æ•´
    - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—§å½¢å¼ã®JSONï¼ˆfx_rate/settlementæœªä¿å­˜ï¼‰ã¯ç¾åœ¨ãƒ¬ãƒ¼ãƒˆã§è¿‘ä¼¼

    Returns
    -------
    dict
        by_symbol: dict[str, float]  éŠ˜æŸ„åˆ¥å®Ÿç¾æç›Š(JPY)
        total_jpy: float  åˆè¨ˆå®Ÿç¾æç›Š(JPY)
    """
    # FIFO: éŠ˜æŸ„ã”ã¨ã«è³¼å…¥ãƒ­ãƒƒãƒˆã‚’ç®¡ç†
    # å„ãƒ­ãƒƒãƒˆ: {"shares": float, "cost_jpy_per_share": float}
    lots: dict[str, list[dict]] = defaultdict(list)
    realized_by_symbol: dict[str, float] = defaultdict(float)

    for trade in trades:
        sym = trade.get("symbol", "")
        tt = trade.get("trade_type", "buy")
        shares = trade.get("shares", 0)
        price = trade.get("price", 0)

        if is_cash(sym):
            continue

        if tt == "buy":
            total_jpy = _trade_cost_jpy(trade, fx_rates)
            cost_per_share = total_jpy / shares if shares > 0 else 0
            lots[sym].append({
                "shares": float(shares),
                "cost_jpy_per_share": cost_per_share,
            })

        elif tt == "transfer":
            if price <= 0 and lots[sym]:
                # Stock split: redistribute cost basis
                existing_shares = sum(lot["shares"] for lot in lots[sym])
                if existing_shares > 0:
                    split_ratio = (existing_shares + shares) / existing_shares
                    for lot in lots[sym]:
                        lot["cost_jpy_per_share"] /= split_ratio
                        lot["shares"] *= split_ratio
            elif price > 0:
                # Regular transfer with cost basis
                total_jpy = _trade_cost_jpy(trade, fx_rates)
                cost_per_share = total_jpy / shares if shares > 0 else 0
                lots[sym].append({
                    "shares": float(shares),
                    "cost_jpy_per_share": cost_per_share,
                })

        elif tt == "sell":
            total_jpy = _trade_cost_jpy(trade, fx_rates)
            proceeds_per_share = total_jpy / shares if shares > 0 else 0

            remaining = float(shares)
            while remaining > 0.5 and lots[sym]:
                lot = lots[sym][0]
                take = min(remaining, lot["shares"])
                pnl = take * (proceeds_per_share - lot["cost_jpy_per_share"])
                realized_by_symbol[sym] += pnl
                lot["shares"] -= take
                remaining -= take
                if lot["shares"] < 0.5:
                    lots[sym].pop(0)

    total = sum(realized_by_symbol.values())
    return {
        "by_symbol": dict(realized_by_symbol),
        "total_jpy": total,
    }


def _build_trade_activity(
    trades: list[dict],
    fx_rates: dict[str, float],
) -> pd.DataFrame:
    """æœˆã”ã¨ã®å£²è²·ä»¶æ•°ãƒ»é‡‘é¡ã‚’ã¾ã¨ã‚ãŸ DataFrame ã‚’è¿”ã™."""
    rows: list[dict] = []
    for trade in trades:
        shares = trade.get("shares", 0)
        price = trade.get("price", 0)
        currency = trade.get("currency", "JPY")
        rate = fx_rates.get(currency, 1.0)
        amount = shares * price * rate
        tt = trade.get("trade_type", "buy")
        d = trade.get("date", "")
        if not d:
            continue
        month = d[:7]  # YYYY-MM
        rows.append({
            "month": month,
            "trade_type": tt,
            "amount_jpy": amount,
        })

    if not rows:
        return pd.DataFrame()

    df = pd.DataFrame(rows)
    buy_df = df[df["trade_type"].isin(["buy", "transfer"])].groupby("month").agg(
        buy_count=("amount_jpy", "count"),
        buy_amount=("amount_jpy", "sum"),
    )
    sell_df = df[df["trade_type"] == "sell"].groupby("month").agg(
        sell_count=("amount_jpy", "count"),
        sell_amount=("amount_jpy", "sum"),
    )
    result = buy_df.join(sell_df, how="outer").fillna(0)
    result["net_flow"] = result["buy_amount"] - result["sell_amount"]
    result.index.name = None
    return result.sort_index()


# ---------------------------------------------------------------------------
# 3. è³‡ç”£æ¨ç§»ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
# ---------------------------------------------------------------------------

# ---------------------------------------------------------------------------
# æœŸé–“ â†’ yfinance period / start ã®å¤‰æ›
# ---------------------------------------------------------------------------

_PERIOD_MAP: dict[str, str | None] = {
    "1mo":  "1mo",
    "3mo":  "3mo",
    "6mo":  "6mo",
    "1y":   "1y",
    "2y":   "2y",
    "3y":   "3y",
    "5y":   "5y",
    "max":  "max",
    "all":  "max",
}


def _fetch_price_history(
    symbol: str, period: str,
) -> Optional[pd.DataFrame]:
    """æœŸé–“æŒ‡å®šã«å¿œã˜ãŸæ ªä¾¡å±¥æ­´ã‚’å–å¾—ã™ã‚‹ (å€‹åˆ¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨)."""
    yf_period = _PERIOD_MAP.get(period, period)
    hist = yahoo_client.get_price_history(symbol, period=yf_period)
    if hist is not None and not hist.empty:
        return hist[["Close"]].rename(columns={"Close": symbol})
    return None


# ---------------------------------------------------------------------------
# ä¾¡æ ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ (ãƒ‡ã‚£ã‚¹ã‚¯ + ãƒãƒƒãƒå–å¾—)
# ---------------------------------------------------------------------------

def _get_cache_path(period: str) -> Path:
    """æœŸé–“ã”ã¨ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™."""
    safe = period.replace("/", "_")
    return _PRICE_CACHE_DIR / f"close_{safe}.csv"


def _load_cached_prices(period: str) -> Optional[pd.DataFrame]:
    """ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰æ ªä¾¡ã‚’èª­ã¿è¾¼ã‚€. TTL è¶…éæ™‚ã¯ None."""
    path = _get_cache_path(period)
    if not path.exists():
        return None
    age = _time.time() - path.stat().st_mtime
    if age > _CACHE_TTL_SECONDS:
        return None
    try:
        df = pd.read_csv(path, index_col=0, parse_dates=True)
        return df if not df.empty else None
    except Exception:
        return None


def _save_prices_cache(prices: pd.DataFrame, period: str) -> None:
    """æ ªä¾¡ã‚’ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜."""
    try:
        _PRICE_CACHE_DIR.mkdir(parents=True, exist_ok=True)
        prices.to_csv(_get_cache_path(period))
    except Exception as e:
        print(f"[data_loader] Cache save error: {e}")


def _load_prices(symbols: list[str], period: str) -> pd.DataFrame:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥å„ªå…ˆã§å…¨éŠ˜æŸ„ã®çµ‚å€¤ã‚’ä¸€æ‹¬å–å¾—.

    1. ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ (TTL 4h) â†’ å³åº§ã«è¿”ã™
    2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¸è¶³éŠ˜æŸ„ â†’ ä¸è¶³åˆ†ã®ã¿ãƒãƒƒãƒå–å¾—ã—ã¦ãƒãƒ¼ã‚¸
    3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã— â†’ å…¨éŠ˜æŸ„ã‚’ãƒãƒƒãƒå–å¾— (yf.download 1 å›)
    """
    yf_period = _PERIOD_MAP.get(period, period)

    # --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ ---
    cached = _load_cached_prices(period)
    if cached is not None:
        missing = [s for s in symbols if s not in cached.columns]
        if not missing:
            available = [s for s in symbols if s in cached.columns]
            print(f"[data_loader] Cache hit: {period} ({len(available)} symbols)")
            return cached[available]
        # ä¸è¶³éŠ˜æŸ„ã®ã¿è¿½åŠ å–å¾—
        print(f"[data_loader] Cache partial: fetching {len(missing)} symbols")
        new_prices = yahoo_client.get_close_prices_batch(missing, period=yf_period)
        if new_prices is not None and not new_prices.empty:
            new_prices.index = pd.to_datetime(new_prices.index).tz_localize(None)
            merged = pd.concat([cached, new_prices], axis=1)
            _save_prices_cache(merged, period)
            available = [s for s in symbols if s in merged.columns]
            if available:
                return merged[available].sort_index().ffill()
        available = [s for s in symbols if s in cached.columns]
        return cached[available] if available else pd.DataFrame()

    # --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹: ãƒãƒƒãƒå–å¾— ---
    print(f"[data_loader] Cache miss: batch-fetching {len(symbols)} symbols")
    prices = yahoo_client.get_close_prices_batch(symbols, period=yf_period)
    if prices is None or prices.empty:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å€‹åˆ¥å–å¾—
        print("[data_loader] Batch failed, falling back to individual fetches")
        frames: dict[str, pd.Series] = {}
        for sym in symbols:
            hist = _fetch_price_history(sym, period)
            if hist is not None and sym in hist.columns:
                frames[sym] = hist[sym]
        if not frames:
            return pd.DataFrame()
        prices = pd.DataFrame(frames)
    prices.index = pd.to_datetime(prices.index).tz_localize(None)
    prices = prices.sort_index().ffill()
    _save_prices_cache(prices, period)
    return prices


def build_portfolio_history(
    csv_path: str = DEFAULT_CSV_PATH,
    base_dir: str = _DEFAULT_HISTORY_DIR,
    period: str = "3mo",
) -> pd.DataFrame:
    """ä¿æœ‰éŠ˜æŸ„ã®æ—¥æ¬¡è©•ä¾¡é¡æ¨ç§»ã‚’ DataFrame ã§è¿”ã™.

    å£²è²·å±¥æ­´ã‹ã‚‰å„æ—¥ã®ä¿æœ‰éŠ˜æŸ„ãƒ»æ ªæ•°ã‚’å¾©å…ƒã—ã€
    yfinance ã®ä¾¡æ ¼å±¥æ­´ã¨æ›ã‘åˆã‚ã›ã¦æ—¥æ¬¡è©•ä¾¡é¡ã‚’ç®—å‡ºã™ã‚‹ã€‚

    Parameters
    ----------
    csv_path : str
        portfolio.csv ã®ãƒ‘ã‚¹
    base_dir : str | None
        history_store ã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    period : str
        æ ªä¾¡å–å¾—æœŸé–“ ("1mo" .. "5y", "max", "all")

    Returns
    -------
    pd.DataFrame
        index=Date, columns=éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«, values=å††æ›ç®—è©•ä¾¡é¡
        + "total" ã‚«ãƒ©ãƒ  + "invested" ã‚«ãƒ©ãƒ 
    """
    trades = _build_holdings_timeline(base_dir)
    if not trades:
        return pd.DataFrame()

    daily_snapshots = _reconstruct_daily_holdings(trades)

    # ç¾åœ¨ä¿æœ‰ä¸­ã®éŠ˜æŸ„ï¼ˆç›´è¿‘ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ï¼‰ï¼‹éå»ã«ä¿æœ‰ã—ã¦ã„ãŸéŠ˜æŸ„
    all_symbols: set[str] = set()
    for snap in daily_snapshots.values():
        all_symbols.update(snap.keys())

    # CASH éŠ˜æŸ„ã¯é™¤å¤–ï¼ˆç‚ºæ›¿æ¨ç§»ã®ã¿ã§ã®è¡¨ç¤ºã¯åˆ¥é€”å¯¾å¿œå¯èƒ½ï¼‰
    stock_symbols = sorted(s for s in all_symbols if not is_cash(s))

    if not stock_symbols:
        return pd.DataFrame()

    # ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆå–å¾—
    fx_rates = get_fx_rates(yahoo_client)

    # å…¨éŠ˜æŸ„ã®çµ‚å€¤ã‚’ä¸€æ‹¬å–å¾—ï¼ˆãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ + ãƒãƒƒãƒå–å¾—ï¼‰
    price_df = _load_prices(stock_symbols, period)
    if price_df.empty:
        return pd.DataFrame()

    # å£²è²·æ—¥ â†’ ä¿æœ‰æ ªæ•°ã®ãƒãƒƒãƒ”ãƒ³ã‚° â€” æ—¥æ¬¡ã«å±•é–‹
    dates = price_df.index
    first_trade_date = pd.Timestamp(trades[0].get("date", ""))

    # å„æ—¥ã®ä¿æœ‰æ ªæ•°ã‚’ computed
    sorted_trade_dates = sorted(daily_snapshots.keys())

    def get_holdings_at(ts: pd.Timestamp) -> dict[str, int]:
        """æŒ‡å®šæ—¥æ™‚ç‚¹ã®ä¿æœ‰æ ªæ•°ã‚’è¿”ã™."""
        result: dict[str, int] = {}
        for td in sorted_trade_dates:
            if pd.Timestamp(td) <= ts:
                result = daily_snapshots[td]
            else:
                break
        return result

    # æ—¥æ¬¡è©•ä¾¡é¡ã®è¨ˆç®—
    eval_data: dict[str, list[float]] = {s: [] for s in stock_symbols}

    for dt in dates:
        holdings = get_holdings_at(dt)
        for symbol in stock_symbols:
            shares = holdings.get(symbol, 0)
            if shares > 0 and symbol in price_df.columns:
                price_val = price_df.loc[dt, symbol]
                if pd.notna(price_val):
                    currency = infer_currency(symbol)
                    rate = fx_rates.get(currency, 1.0)
                    eval_data[symbol].append(shares * price_val * rate)
                else:
                    eval_data[symbol].append(0.0)
            else:
                eval_data[symbol].append(0.0)

    result_df = pd.DataFrame(eval_data, index=dates)

    # å–å¼•é–‹å§‹å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–
    if not first_trade_date or pd.isna(first_trade_date):
        first_trade_date = dates[0]
    result_df = result_df[result_df.index >= first_trade_date]

    # å…¨æœŸé–“ã‚¼ãƒ­ã®éŠ˜æŸ„åˆ—ã‚’é™¤å¤–ï¼ˆæ—¢ã«å£²å´æ¸ˆã¿ã§è¡¨ç¤ºæœŸé–“ã«ä¿æœ‰ãŒãªã„éŠ˜æŸ„ï¼‰
    symbol_cols = [c for c in result_df.columns if c not in ("total", "invested")]
    zero_cols = [c for c in symbol_cols if (result_df[c] == 0).all()]
    if zero_cols:
        result_df = result_df.drop(columns=zero_cols)

    # åˆè¨ˆåˆ—
    result_df["total"] = result_df.sum(axis=1)

    # ç´¯ç©æŠ•è³‡é¡åˆ—ã®è¿½åŠ 
    invested_map = _compute_invested_capital(trades, fx_rates)
    invested_series: list[float] = []
    sorted_inv_dates = sorted(invested_map.keys())
    for dt in result_df.index:
        inv_val = 0.0
        for inv_d in sorted_inv_dates:
            if pd.Timestamp(inv_d) <= dt:
                inv_val = invested_map[inv_d]
            else:
                break
        invested_series.append(inv_val)
    result_df["invested"] = invested_series

    return result_df


# ---------------------------------------------------------------------------
# 4. ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥é›†è¨ˆ
# ---------------------------------------------------------------------------

def get_sector_breakdown(snapshot: dict) -> pd.DataFrame:
    """ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥è©•ä¾¡é¡ã‚’é›†è¨ˆ."""
    rows = []
    for p in snapshot["positions"]:
        rows.append({
            "sector": p.get("sector") or "Unknown",
            "evaluation_jpy": p.get("evaluation_jpy", 0),
        })
    df = pd.DataFrame(rows)
    if df.empty:
        return df
    return df.groupby("sector")["evaluation_jpy"].sum().reset_index()


# ---------------------------------------------------------------------------
# 5. æœˆæ¬¡é›†è¨ˆ
# ---------------------------------------------------------------------------

def get_monthly_summary(history_df: pd.DataFrame) -> pd.DataFrame:
    """æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœˆæœ«ã® total ã‚’æŠ½å‡ºã—ã¦æœˆæ¬¡ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¿”ã™."""
    if history_df.empty:
        return pd.DataFrame()

    cols = ["total"]
    if "invested" in history_df.columns:
        cols.append("invested")

    monthly = history_df[cols].resample("ME").last()
    monthly.index = monthly.index.strftime("%Y-%m")
    rename = {"total": "month_end_value_jpy"}
    if "invested" in monthly.columns:
        rename["invested"] = "invested_jpy"
    monthly = monthly.rename(columns=rename)

    # æœˆæ¬¡å¤‰å‹•ç‡
    monthly["change_pct"] = monthly["month_end_value_jpy"].pct_change() * 100

    # å‰å¹´åŒæœˆæ¯” (YoY)
    monthly["yoy_pct"] = monthly["month_end_value_jpy"].pct_change(periods=12) * 100

    # å«ã¿æç›Š
    if "invested_jpy" in monthly.columns:
        monthly["unrealized_pnl"] = (
            monthly["month_end_value_jpy"] - monthly["invested_jpy"]
        )

    return monthly


def get_trade_activity(
    base_dir: str = _DEFAULT_HISTORY_DIR,
) -> pd.DataFrame:
    """æœˆã”ã¨ã®å£²è²·ä»¶æ•°ãƒ»é‡‘é¡ã‚’è¿”ã™."""
    trades = _build_holdings_timeline(base_dir)
    if not trades:
        return pd.DataFrame()
    fx_rates = get_fx_rates(yahoo_client)
    return _build_trade_activity(trades, fx_rates)


# ---------------------------------------------------------------------------
# 6. è³‡ç”£æ¨å®šæ¨ç§»ï¼ˆæ¥½è¦³/ãƒ™ãƒ¼ã‚¹/æ‚²è¦³ï¼‰
# ---------------------------------------------------------------------------

def build_projection(
    current_value: float,
    years: int = 5,
    optimistic_rate: float | None = None,
    base_rate: float | None = None,
    pessimistic_rate: float | None = None,
    csv_path: str = DEFAULT_CSV_PATH,
) -> pd.DataFrame:
    """ç¾åœ¨ã®ç·è³‡ç”£ã‹ã‚‰æ¥½è¦³/ãƒ™ãƒ¼ã‚¹/æ‚²è¦³ã®å°†æ¥æ¨å®šæ¨ç§»ã‚’ç”Ÿæˆã™ã‚‹.

    Parameters
    ----------
    current_value : float
        ç¾åœ¨ã®ç·è³‡ç”£ï¼ˆå††ï¼‰ã€‚
    years : int
        ä½•å¹´å…ˆã¾ã§æ¨å®šã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5å¹´ï¼‰ã€‚
    optimistic_rate, base_rate, pessimistic_rate : float | None
        å¹´ç‡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆ0.10 = 10%ï¼‰ã€‚None ã®å ´åˆã¯ estimate_portfolio_return ã‹ã‚‰å–å¾—ã€‚
    csv_path : str
        ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªCSVãƒ‘ã‚¹ã€‚

    Returns
    -------
    pd.DataFrame
        index=æ—¥ä»˜, columns=[optimistic, base, pessimistic]
    """
    # ãƒªã‚¿ãƒ¼ãƒ³æ¨å®šå€¤ãŒæœªæŒ‡å®šã®å ´åˆã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‹ã‚‰æ¨å®š
    if base_rate is None:
        try:
            from src.core.return_estimate import estimate_portfolio_return
            result = estimate_portfolio_return(csv_path, yahoo_client)
            pf = result.get("portfolio", {})
            optimistic_rate = pf.get("optimistic") or 0.15
            base_rate = pf.get("base") or 0.08
            pessimistic_rate = pf.get("pessimistic") or -0.05
        except Exception:
            optimistic_rate = 0.15
            base_rate = 0.08
            pessimistic_rate = -0.05

    if optimistic_rate is None:
        optimistic_rate = 0.15
    if pessimistic_rate is None:
        pessimistic_rate = -0.05

    # æœˆæ¬¡ãƒã‚¤ãƒ³ãƒˆã§æ¨å®šï¼ˆyears * 12 + 1 ç‚¹ï¼‰
    today = pd.Timestamp.now().normalize()
    months = years * 12
    dates = pd.date_range(start=today, periods=months + 1, freq="ME")
    # å…ˆé ­ã‚’ä»Šæ—¥ã«ã™ã‚‹
    dates = dates.insert(0, today)

    rows = []
    for d in dates:
        t_years = (d - today).days / 365.25
        rows.append({
            "date": d,
            "optimistic": current_value * (1 + optimistic_rate) ** t_years,
            "base": current_value * (1 + base_rate) ** t_years,
            "pessimistic": current_value * (1 + pessimistic_rate) ** t_years,
        })

    df = pd.DataFrame(rows).set_index("date")
    return df


# ---------------------------------------------------------------------------
# 7. ãƒªã‚¹ã‚¯æŒ‡æ¨™ã®ç®—å‡º
# ---------------------------------------------------------------------------

import numpy as np


def compute_risk_metrics(history_df: pd.DataFrame) -> dict:
    """æ—¥æ¬¡ã®è³‡ç”£æ¨ç§»ã‹ã‚‰ãƒªã‚¹ã‚¯æŒ‡æ¨™ã‚’ç®—å‡ºã™ã‚‹.

    Parameters
    ----------
    history_df : pd.DataFrame
        build_portfolio_history() ã®å‡ºåŠ›ã€‚"total" åˆ—ãŒå¿…é ˆã€‚

    Returns
    -------
    dict
        sharpe_ratio: float   å¹´ç‡ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªï¼ˆãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆ0.5%æƒ³å®šï¼‰
        max_drawdown_pct: float  æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ï¼ˆ%ã€ãƒã‚¤ãƒŠã‚¹å€¤ï¼‰
        annual_volatility_pct: float  å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ%ï¼‰
        annual_return_pct: float  å¹´ç‡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆ%ï¼‰
        calmar_ratio: float  ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ªï¼ˆå¹´ç‡ãƒªã‚¿ãƒ¼ãƒ³ / |MDD|ï¼‰
    """
    if history_df.empty or "total" not in history_df.columns:
        return {
            "sharpe_ratio": 0.0,
            "max_drawdown_pct": 0.0,
            "annual_volatility_pct": 0.0,
            "annual_return_pct": 0.0,
            "calmar_ratio": 0.0,
        }

    total = history_df["total"].dropna()
    if len(total) < 2:
        return {
            "sharpe_ratio": 0.0,
            "max_drawdown_pct": 0.0,
            "annual_volatility_pct": 0.0,
            "annual_return_pct": 0.0,
            "calmar_ratio": 0.0,
        }

    # æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³
    daily_returns = total.pct_change().dropna()
    if daily_returns.empty:
        return {
            "sharpe_ratio": 0.0,
            "max_drawdown_pct": 0.0,
            "annual_volatility_pct": 0.0,
            "annual_return_pct": 0.0,
            "calmar_ratio": 0.0,
        }

    trading_days = 252
    risk_free_rate = 0.005  # 0.5%

    # å¹´ç‡ãƒªã‚¿ãƒ¼ãƒ³
    total_days = (total.index[-1] - total.index[0]).days
    if total_days <= 0:
        total_days = 1
    total_return = total.iloc[-1] / total.iloc[0] - 1
    annual_return = (1 + total_return) ** (365.25 / total_days) - 1

    # å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    annual_vol = float(daily_returns.std() * np.sqrt(trading_days))

    # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª
    sharpe = (annual_return - risk_free_rate) / annual_vol if annual_vol > 0 else 0.0

    # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
    cummax = total.cummax()
    drawdown = (total - cummax) / cummax
    max_dd = float(drawdown.min()) * 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆ

    # ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ª
    calmar = annual_return / abs(max_dd / 100) if max_dd != 0 else 0.0

    return {
        "sharpe_ratio": round(float(sharpe), 2),
        "max_drawdown_pct": round(max_dd, 1),
        "annual_volatility_pct": round(annual_vol * 100, 1),
        "annual_return_pct": round(annual_return * 100, 1),
        "calmar_ratio": round(float(calmar), 2),
    }


# ---------------------------------------------------------------------------
# 8. Top/Worst ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ¼
# ---------------------------------------------------------------------------

def compute_top_worst_performers(
    history_df: pd.DataFrame,
    top_n: int = 3,
) -> dict:
    """ç›´è¿‘1æ—¥ã®éŠ˜æŸ„åˆ¥é¨°è½ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¿”ã™.

    Parameters
    ----------
    history_df : pd.DataFrame
        build_portfolio_history() ã®å‡ºåŠ›
    top_n : int
        ä¸Šä½/ä¸‹ä½ä½•éŠ˜æŸ„ã‚’è¿”ã™ã‹

    Returns
    -------
    dict
        top: list[dict]  (symbol, change_pct, change_jpy)
        worst: list[dict]
    """
    if history_df.empty or len(history_df) < 2:
        return {"top": [], "worst": []}

    stock_cols = [c for c in history_df.columns if c not in ("total", "invested")]
    if not stock_cols:
        return {"top": [], "worst": []}

    latest = history_df.iloc[-1]
    previous = history_df.iloc[-2]

    performers = []
    for col in stock_cols:
        cur = float(latest.get(col, 0))
        prev = float(previous.get(col, 0))
        if prev > 0 and cur > 0:
            pct = (cur / prev - 1) * 100
            change_jpy = cur - prev
            performers.append({
                "symbol": col,
                "change_pct": round(pct, 2),
                "change_jpy": round(change_jpy, 0),
            })

    performers.sort(key=lambda x: x["change_pct"], reverse=True)

    actual_n = min(top_n, len(performers))
    return {
        "top": performers[:actual_n],
        "worst": performers[-actual_n:][::-1] if actual_n > 0 else [],
    }


# ---------------------------------------------------------------------------
# 9. å‰æ—¥æ¯”è¨ˆç®—
# ---------------------------------------------------------------------------

def compute_daily_change(history_df: pd.DataFrame) -> dict:
    """ç›´è¿‘ã®å‰æ—¥æ¯”ï¼ˆé‡‘é¡ãƒ»ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆï¼‰ã‚’ç®—å‡ºã™ã‚‹.

    Parameters
    ----------
    history_df : pd.DataFrame
        build_portfolio_history() ã®å‡ºåŠ›ã€‚"total" åˆ—ãŒå¿…é ˆã€‚

    Returns
    -------
    dict
        daily_change_jpy: float  å‰æ—¥æ¯”ï¼ˆå††ï¼‰
        daily_change_pct: float  å‰æ—¥æ¯”ï¼ˆ%ï¼‰
    """
    if history_df.empty or "total" not in history_df.columns:
        return {"daily_change_jpy": 0.0, "daily_change_pct": 0.0}

    total = history_df["total"].dropna()
    if len(total) < 2:
        return {"daily_change_jpy": 0.0, "daily_change_pct": 0.0}

    latest = float(total.iloc[-1])
    previous = float(total.iloc[-2])
    change = latest - previous
    pct = (change / previous * 100) if previous != 0 else 0.0

    return {
        "daily_change_jpy": round(change, 0),
        "daily_change_pct": round(pct, 2),
    }


# ---------------------------------------------------------------------------
# 9. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è¶…éãƒªã‚¿ãƒ¼ãƒ³
# ---------------------------------------------------------------------------

def compute_benchmark_excess(
    history_df: pd.DataFrame,
    benchmark_series: pd.Series | None,
) -> dict | None:
    """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’ç®—å‡ºã™ã‚‹.

    Parameters
    ----------
    history_df : pd.DataFrame
        build_portfolio_history() ã®å‡ºåŠ›ã€‚"total" åˆ—ãŒå¿…é ˆã€‚
    benchmark_series : pd.Series | None
        get_benchmark_series() ã®å‡ºåŠ›ï¼ˆæ­£è¦åŒ–æ¸ˆã¿ï¼‰

    Returns
    -------
    dict | None
        portfolio_return_pct: float
        benchmark_return_pct: float
        excess_return_pct: float
    """
    if benchmark_series is None or history_df.empty or "total" not in history_df.columns:
        return None

    total = history_df["total"].dropna()
    bench = benchmark_series.dropna()
    if len(total) < 2 or len(bench) < 2:
        return None

    pf_return = (float(total.iloc[-1]) / float(total.iloc[0]) - 1) * 100
    bm_return = (float(bench.iloc[-1]) / float(bench.iloc[0]) - 1) * 100
    excess = pf_return - bm_return

    return {
        "portfolio_return_pct": round(pf_return, 2),
        "benchmark_return_pct": round(bm_return, 2),
        "excess_return_pct": round(excess, 2),
    }


# ---------------------------------------------------------------------------
# 10. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿å–å¾—
# ---------------------------------------------------------------------------

def get_benchmark_series(
    symbol: str,
    history_df: pd.DataFrame,
    period: str = "3mo",
) -> pd.Series | None:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯éŠ˜æŸ„ã®çµ‚å€¤ã‚’å–å¾—ã—ã€PF ã® total åˆ—ã¨åŒã˜åŸºæº–ã«æ­£è¦åŒ–ã™ã‚‹.

    PF é–‹å§‹æ—¥ã® total å€¤ã‚’åŸºæº–ã«ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’
    åŒã˜å††ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›ã—ã¦è¿”ã™ã€‚

    Parameters
    ----------
    symbol : str
        ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ (e.g. "SPY", "^N225")
    history_df : pd.DataFrame
        build_portfolio_history() ã®å‡ºåŠ›
    period : str
        ä¾¡æ ¼å–å¾—æœŸé–“

    Returns
    -------
    pd.Series | None
        index=Date, values=æ­£è¦åŒ–ã•ã‚ŒãŸè©•ä¾¡é¡ï¼ˆPFã¨åŒã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    """
    if history_df.empty or "total" not in history_df.columns:
        return None

    prices = _load_prices([symbol], period)
    if prices.empty or symbol not in prices.columns:
        return None

    bench = prices[symbol].dropna()
    if bench.empty:
        return None

    # PF ã®æ—¥ä»˜ç¯„å›²ã«åˆã‚ã›ã‚‹
    pf_start = history_df.index[0]
    bench = bench[bench.index >= pf_start]
    if bench.empty:
        return None

    # PF é–‹å§‹æ—¥ã® total ã‚’åŸºæº–ã«æ­£è¦åŒ–
    pf_start_value = history_df["total"].iloc[0]
    bench_start_value = bench.iloc[0]
    if bench_start_value == 0:
        return None

    normalized = bench / bench_start_value * pf_start_value
    normalized.name = symbol
    return normalized


# ---------------------------------------------------------------------------
# 12. ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ç³»åˆ—
# ---------------------------------------------------------------------------

def compute_drawdown_series(history_df: pd.DataFrame) -> pd.Series:
    """æ—¥æ¬¡ã®ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ï¼ˆãƒ”ãƒ¼ã‚¯ã‹ã‚‰ã®ä¸‹è½ç‡ %ï¼‰ç³»åˆ—ã‚’è¿”ã™.

    Parameters
    ----------
    history_df : pd.DataFrame
        build_portfolio_history() ã®å‡ºåŠ›ã€‚"total" åˆ—ãŒå¿…é ˆã€‚

    Returns
    -------
    pd.Series
        index=Date, values=ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ï¼ˆ%ã€0ä»¥ä¸‹ã®å€¤ï¼‰
    """
    if history_df.empty or "total" not in history_df.columns:
        return pd.Series(dtype=float)

    total = history_df["total"].dropna()
    if len(total) < 2:
        return pd.Series(dtype=float)

    cummax = total.cummax()
    drawdown = (total - cummax) / cummax * 100
    return drawdown


# ---------------------------------------------------------------------------
# 13. ãƒ­ãƒ¼ãƒªãƒ³ã‚°Sharpeæ¯”ç³»åˆ—
# ---------------------------------------------------------------------------

def compute_rolling_sharpe(
    history_df: pd.DataFrame,
    window: int = 60,
    risk_free_rate: float = 0.005,
) -> pd.Series:
    """ãƒ­ãƒ¼ãƒªãƒ³ã‚°Sharpeæ¯”ã®ç³»åˆ—ã‚’è¿”ã™.

    Parameters
    ----------
    history_df : pd.DataFrame
        build_portfolio_history() ã®å‡ºåŠ›ã€‚"total" åˆ—ãŒå¿…é ˆã€‚
    window : int
        ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆå–¶æ¥­æ—¥æ•°ï¼‰
    risk_free_rate : float
        å¹´ç‡ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ãƒ¬ãƒ¼ãƒˆ

    Returns
    -------
    pd.Series
        index=Date, values=ãƒ­ãƒ¼ãƒªãƒ³ã‚°Sharpeæ¯”ï¼ˆå¹´ç‡æ›ç®—ï¼‰
    """
    if history_df.empty or "total" not in history_df.columns:
        return pd.Series(dtype=float)

    total = history_df["total"].dropna()
    if len(total) < window + 1:
        return pd.Series(dtype=float)

    daily_returns = total.pct_change().dropna()
    trading_days = 252
    daily_rf = (1 + risk_free_rate) ** (1 / trading_days) - 1

    rolling_mean = daily_returns.rolling(window=window).mean()
    rolling_std = daily_returns.rolling(window=window).std()

    rolling_sharpe = (
        (rolling_mean - daily_rf) / rolling_std * np.sqrt(trading_days)
    )
    return rolling_sharpe.dropna()


# ---------------------------------------------------------------------------
# 14. éŠ˜æŸ„é–“ç›¸é–¢è¡Œåˆ—
# ---------------------------------------------------------------------------

def compute_correlation_matrix(
    history_df: pd.DataFrame,
    min_periods: int = 20,
) -> pd.DataFrame:
    """ä¿æœ‰éŠ˜æŸ„é–“ã®æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ç›¸é–¢è¡Œåˆ—ã‚’è¿”ã™.

    Parameters
    ----------
    history_df : pd.DataFrame
        build_portfolio_history() ã®å‡ºåŠ›ã€‚éŠ˜æŸ„ã”ã¨ã®åˆ—ã‚’å«ã‚€ã€‚
    min_periods : int
        ç›¸é–¢è¨ˆç®—ã«å¿…è¦ãªæœ€ä½ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°ã€‚

    Returns
    -------
    pd.DataFrame
        éŠ˜æŸ„Ã—éŠ˜æŸ„ã®ç›¸é–¢è¡Œåˆ—ã€‚éŠ˜æŸ„ãŒ2ã¤æœªæº€ã®å ´åˆã¯ç©ºDataFrameã€‚
    """
    if history_df.empty:
        return pd.DataFrame()

    # "total" ã¨ "invested" ã‚’é™¤ã„ãŸéŠ˜æŸ„åˆ—ã®ã¿
    stock_cols = [c for c in history_df.columns if c not in ("total", "invested")]
    if len(stock_cols) < 2:
        return pd.DataFrame()

    stock_df = history_df[stock_cols].dropna(how="all")
    if len(stock_df) < min_periods:
        return pd.DataFrame()

    # æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—
    daily_returns = stock_df.pct_change().dropna(how="all")

    # ç›¸é–¢è¡Œåˆ—
    corr = daily_returns.corr(min_periods=min_periods)
    return corr


# ---------------------------------------------------------------------------
# 15. ã‚¦ã‚§ã‚¤ãƒˆãƒ‰ãƒªãƒ•ãƒˆåˆ¤å®š
# ---------------------------------------------------------------------------

def compute_weight_drift(
    positions: list[dict],
    total_value_jpy: float,
    target_weights: dict[str, float] | None = None,
    threshold_pct: float = 5.0,
) -> list[dict]:
    """å„éŠ˜æŸ„ã®ç¾åœ¨ã‚¦ã‚§ã‚¤ãƒˆã¨ç›®æ¨™ã‚¦ã‚§ã‚¤ãƒˆã®ä¹–é›¢ã‚’è¨ˆç®—ã—ã€é–¾å€¤è¶…éã‚’è¿”ã™.

    Parameters
    ----------
    positions : list[dict]
        get_current_snapshot()["positions"]
    total_value_jpy : float
        ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç·é¡(å††)
    target_weights : dict[str, float] | None
        éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«â†’ç›®æ¨™ã‚¦ã‚§ã‚¤ãƒˆ(%)ã®ãƒãƒƒãƒ—ã€‚
        None ã®å ´åˆã¯å‡ç­‰ã‚¦ã‚§ã‚¤ãƒˆï¼ˆ= 100 / éŠ˜æŸ„æ•°ï¼‰ã‚’é©ç”¨ã€‚
    threshold_pct : float
        ä¹–é›¢è­¦å‘Šã®é–¾å€¤(ãƒã‚¤ãƒ³ãƒˆ)ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5.0ppã€‚

    Returns
    -------
    list[dict]
        ä¹–é›¢ãŒé–¾å€¤ã‚’è¶…ãˆãŸéŠ˜æŸ„ã®ãƒªã‚¹ãƒˆã€‚å„è¦ç´ :
        - symbol: str
        - name: str
        - current_pct: float  (ç¾åœ¨ã‚¦ã‚§ã‚¤ãƒˆ%)
        - target_pct: float   (ç›®æ¨™ã‚¦ã‚§ã‚¤ãƒˆ%)
        - drift_pct: float    (ä¹–é›¢å¹…pp, æ­£=ã‚ªãƒ¼ãƒãƒ¼ã‚¦ã‚§ã‚¤ãƒˆ)
        - status: str         ("overweight" | "underweight")
    """
    if not positions or total_value_jpy <= 0:
        return []

    # Cash ã‚’é™¤å¤–ã—ãŸéŠ˜æŸ„ã®ã¿å¯¾è±¡
    stock_positions = [p for p in positions if p.get("sector") != "Cash"]
    if not stock_positions:
        return []

    n = len(stock_positions)
    equal_weight = 100.0 / n if n > 0 else 0

    results = []
    for p in stock_positions:
        symbol = p["symbol"]
        current_pct = p["evaluation_jpy"] / total_value_jpy * 100

        if target_weights and symbol in target_weights:
            target_pct = target_weights[symbol]
        else:
            target_pct = equal_weight

        drift = current_pct - target_pct

        if abs(drift) >= threshold_pct:
            results.append({
                "symbol": symbol,
                "name": p.get("name", symbol),
                "current_pct": round(current_pct, 1),
                "target_pct": round(target_pct, 1),
                "drift_pct": round(drift, 1),
                "status": "overweight" if drift > 0 else "underweight",
            })

    # ä¹–é›¢ã®å¤§ãã„é †ã«ã‚½ãƒ¼ãƒˆ
    results.sort(key=lambda x: abs(x["drift_pct"]), reverse=True)
    return results


# ---------------------------------------------------------------------------
# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ï¼‰
# ---------------------------------------------------------------------------

def run_dashboard_health_check(
    csv_path: str = DEFAULT_CSV_PATH,
) -> dict:
    """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨éŠ˜æŸ„ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã™ã‚‹.

    æ—¢å­˜ã® health_check.py ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‘¼ã³å‡ºã—ã€
    ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºç”¨ã«çµæœã‚’æ•´å½¢ã™ã‚‹ã€‚

    Returns
    -------
    dict
        positions: list[dict]  å„éŠ˜æŸ„ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœ
        alerts: list[dict]     ã‚¢ãƒ©ãƒ¼ãƒˆã®ã‚ã‚‹éŠ˜æŸ„ã®ã¿
        sell_alerts: list[dict] å£²ã‚Šã‚¿ã‚¤ãƒŸãƒ³ã‚°é€šçŸ¥
        summary: dict          ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
    """
    positions = load_portfolio(csv_path)

    empty_summary = {
        "total": 0,
        "healthy": 0,
        "early_warning": 0,
        "caution": 0,
        "exit": 0,
    }

    if not positions:
        return {
            "positions": [],
            "alerts": [],
            "sell_alerts": [],
            "summary": empty_summary,
        }

    results: list[dict] = []
    alerts: list[dict] = []
    counts = {"healthy": 0, "early_warning": 0, "caution": 0, "exit": 0}

    for pos in positions:
        symbol = pos["symbol"]

        # Skip cash positions
        if is_cash(symbol):
            continue

        # 1. Trend analysis (1y price history)
        hist = yahoo_client.get_price_history(symbol, period="1y")
        trend_health = check_trend_health(hist)

        # 2. Change quality (alpha signal)
        stock_detail = yahoo_client.get_stock_detail(symbol)
        if stock_detail is None:
            stock_detail = {}
        change_quality = check_change_quality(stock_detail)

        # 3. Shareholder return stability
        sh_return = calculate_shareholder_return(stock_detail)
        sh_history = calculate_shareholder_return_history(stock_detail)
        sh_stability = assess_return_stability(sh_history)

        # 4. Alert level
        alert = compute_alert_level(
            trend_health, change_quality,
            stock_detail=stock_detail,
            return_stability=sh_stability,
        )

        # 5. Long-term suitability
        long_term = check_long_term_suitability(
            stock_detail, shareholder_return_data=sh_return,
        )

        # 6. Value trap detection
        value_trap = detect_value_trap(stock_detail)

        # PnL from portfolio
        shares = pos["shares"]
        cost_price = pos["cost_price"]
        current_price = trend_health.get("current_price", 0)
        if current_price and cost_price:
            pnl_pct = ((current_price / cost_price) - 1) * 100
        else:
            pnl_pct = 0

        result = {
            "symbol": symbol,
            "name": pos.get("memo") or symbol,
            "shares": shares,
            "cost_price": cost_price,
            "current_price": current_price,
            "pnl_pct": round(pnl_pct, 2),
            "trend": trend_health.get("trend", "ä¸æ˜"),
            "rsi": trend_health.get("rsi", float("nan")),
            "sma50": trend_health.get("sma50", 0),
            "sma200": trend_health.get("sma200", 0),
            "price_above_sma50": trend_health.get("price_above_sma50", False),
            "price_above_sma200": trend_health.get("price_above_sma200", False),
            "cross_signal": trend_health.get("cross_signal", "none"),
            "days_since_cross": trend_health.get("days_since_cross"),
            "cross_date": trend_health.get("cross_date"),
            "change_quality": change_quality.get("quality_label", ""),
            "change_score": change_quality.get("change_score", 0),
            "indicators": change_quality.get("indicators", {}),
            "alert_level": alert["level"],
            "alert_emoji": alert["emoji"],
            "alert_label": alert["label"],
            "alert_reasons": alert["reasons"],
            "long_term_label": long_term.get("label", ""),
            "long_term_summary": long_term.get("summary", ""),
            "value_trap": value_trap.get("is_trap", False),
            "value_trap_reasons": value_trap.get("reasons", []),
            "return_stability": sh_stability.get("stability", ""),
            "return_stability_emoji": _stability_emoji(
                sh_stability.get("stability", "")
            ),
        }
        results.append(result)

        if alert["level"] != ALERT_NONE:
            alerts.append(result)
            counts[alert["level"]] = counts.get(alert["level"], 0) + 1
        else:
            counts["healthy"] += 1

    # å£²ã‚Šã‚¿ã‚¤ãƒŸãƒ³ã‚°é€šçŸ¥ã‚’ç”Ÿæˆ
    sell_alerts = _compute_sell_alerts(results)

    return {
        "positions": results,
        "alerts": alerts,
        "sell_alerts": sell_alerts,
        "summary": {
            "total": len(results),
            **counts,
        },
    }


def _stability_emoji(stability: str) -> str:
    """é‚„å…ƒå®‰å®šåº¦ã®ã‚¨ãƒ¢ã‚¸ã‚’è¿”ã™."""
    return {
        "stable": "âœ…",
        "increasing": "ğŸ“ˆ",
        "temporary": "âš ï¸",
        "decreasing": "ğŸ“‰",
    }.get(stability, "")


def _compute_sell_alerts(positions: list[dict]) -> list[dict]:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœã‹ã‚‰å£²ã‚Šã‚¿ã‚¤ãƒŸãƒ³ã‚°é€šçŸ¥ã‚’ç”Ÿæˆã™ã‚‹.

    ä»¥ä¸‹ã®æ¡ä»¶ã§é€šçŸ¥ã‚’ç”Ÿæˆ:
    1. EXIT ã‚¢ãƒ©ãƒ¼ãƒˆ â†’ å³åº§ã«å£²å´æ¤œè¨
    2. CAUTION + å«ã¿æ â†’ æåˆ‡ã‚Šæ¤œè¨
    3. ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹ç›´è¿‘ç™ºç”Ÿ â†’ ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›æ³¨æ„
    4. RSI 30ä»¥ä¸‹ â†’ å£²ã‚‰ã‚Œéãï¼ˆåç™º or æ›´ãªã‚‹ä¸‹è½ï¼‰
    5. ãƒãƒªãƒ¥ãƒ¼ãƒˆãƒ©ãƒƒãƒ—æ¤œå‡º â†’ å‰²å®‰ç½ ã‹ã‚‰ã®æ’¤é€€æ¤œè¨
    6. å«ã¿ç›ŠãŒå¤§ãã„ + ãƒˆãƒ¬ãƒ³ãƒ‰ä¸‹é™ â†’ åˆ©ç¢ºæ¤œè¨

    Returns
    -------
    list[dict]
        å„é€šçŸ¥: symbol, name, urgency (critical/warning/info),
        action, reason, details
    """
    alerts: list[dict] = []

    for pos in positions:
        symbol = pos["symbol"]
        name = pos["name"]
        alert_level = pos["alert_level"]
        pnl_pct = pos["pnl_pct"]
        trend = pos["trend"]
        rsi = pos.get("rsi", float("nan"))
        cross_signal = pos.get("cross_signal", "none")
        days_since_cross = pos.get("days_since_cross")
        value_trap = pos.get("value_trap", False)
        reasons = pos.get("alert_reasons", [])

        # 1. EXIT â†’ å³å£²å´æ¤œè¨ï¼ˆæœ€é«˜å„ªå…ˆåº¦ï¼‰
        if alert_level == ALERT_EXIT:
            alerts.append({
                "symbol": symbol,
                "name": name,
                "urgency": "critical",
                "action": "å£²å´æ¤œè¨",
                "reason": "EXIT ã‚·ã‚°ãƒŠãƒ«: ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«å´©å£Š + ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«æ‚ªåŒ–",
                "details": reasons,
                "pnl_pct": pnl_pct,
            })
            continue  # EXIT ã®å ´åˆã¯ä»–ã®é€šçŸ¥ã¯ä¸è¦

        # 2. CAUTION + å«ã¿æ â†’ æåˆ‡ã‚Šæ¤œè¨
        if alert_level == ALERT_CAUTION and pnl_pct < -5:
            alerts.append({
                "symbol": symbol,
                "name": name,
                "urgency": "critical",
                "action": "æåˆ‡ã‚Šæ¤œè¨",
                "reason": f"æ³¨æ„ã‚¢ãƒ©ãƒ¼ãƒˆ & å«ã¿æ {pnl_pct:+.1f}%",
                "details": reasons,
                "pnl_pct": pnl_pct,
            })
            continue

        # 3. CAUTIONï¼ˆå«ã¿æãªã—ï¼‰â†’ è­¦å‘Š
        if alert_level == ALERT_CAUTION:
            alerts.append({
                "symbol": symbol,
                "name": name,
                "urgency": "warning",
                "action": "æ³¨è¦–ãƒ»ä¸€éƒ¨å£²å´æ¤œè¨",
                "reason": "æ³¨æ„ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç”Ÿ",
                "details": reasons,
                "pnl_pct": pnl_pct,
            })

        # 4. å«ã¿ç›Š +20% ä»¥ä¸Š + ãƒˆãƒ¬ãƒ³ãƒ‰ä¸‹é™ â†’ åˆ©ç¢ºæ¤œè¨
        if pnl_pct >= 20 and trend == "ä¸‹é™":
            alerts.append({
                "symbol": symbol,
                "name": name,
                "urgency": "warning",
                "action": "åˆ©ç¢ºæ¤œè¨",
                "reason": f"å«ã¿ç›Š {pnl_pct:+.1f}% ã ãŒãƒˆãƒ¬ãƒ³ãƒ‰ä¸‹é™ä¸­",
                "details": [
                    f"å«ã¿ç›Š {pnl_pct:+.1f}% ã‚’ç¢ºä¿ã§ãã‚‹ã†ã¡ã«ä¸€éƒ¨åˆ©ç¢ºã‚’æ¤œè¨",
                    "ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã§å«ã¿ç›ŠãŒç¸®å°ã™ã‚‹ãƒªã‚¹ã‚¯",
                ],
                "pnl_pct": pnl_pct,
            })

        # 5. ç›´è¿‘ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹ï¼ˆ10æ—¥ä»¥å†…ï¼‰â†’ æ³¨æ„
        if (cross_signal == "death_cross"
                and days_since_cross is not None
                and days_since_cross <= 10):
            # EXIT/CAUTION ã§æ—¢ã«é€šçŸ¥ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if alert_level not in (ALERT_EXIT, ALERT_CAUTION):
                alerts.append({
                    "symbol": symbol,
                    "name": name,
                    "urgency": "warning",
                    "action": "ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›æ³¨æ„",
                    "reason": f"ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹ç™ºç”Ÿï¼ˆ{days_since_cross}æ—¥å‰ï¼‰",
                    "details": [
                        f"SMA50ãŒSMA200ã‚’ä¸‹å›ã£ãŸï¼ˆ{pos.get('cross_date', '')}ï¼‰",
                        "ä¸­é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã®ä¸‹é™è»¢æ›ã‚·ã‚°ãƒŠãƒ«",
                    ],
                    "pnl_pct": pnl_pct,
                })

        # 6. ãƒãƒªãƒ¥ãƒ¼ãƒˆãƒ©ãƒƒãƒ—æ¤œå‡º â†’ æ³¨æ„
        if value_trap:
            alerts.append({
                "symbol": symbol,
                "name": name,
                "urgency": "warning",
                "action": "ãƒãƒªãƒ¥ãƒ¼ãƒˆãƒ©ãƒƒãƒ—æ³¨æ„",
                "reason": "è¦‹ã›ã‹ã‘ã®å‰²å®‰ï¼ˆä½PER + åˆ©ç›Šæ¸›å°‘ï¼‰",
                "details": pos.get("value_trap_reasons", []),
                "pnl_pct": pnl_pct,
            })

        # 7. RSI 30ä»¥ä¸‹ â†’ æƒ…å ±
        if not _is_nan(rsi) and rsi <= 30:
            alerts.append({
                "symbol": symbol,
                "name": name,
                "urgency": "info",
                "action": "RSI å£²ã‚‰ã‚Œéã",
                "reason": f"RSI = {rsi:.1f}ï¼ˆ30ä»¥ä¸‹ï¼‰",
                "details": [
                    "å£²ã‚‰ã‚Œéãæ°´æº– â€” åç™ºã®å¯èƒ½æ€§ã‚‚ã‚ã‚‹ãŒæ›´ãªã‚‹ä¸‹è½ãƒªã‚¹ã‚¯ã‚‚",
                    "ä»–ã®æŒ‡æ¨™ã¨åˆã‚ã›ã¦åˆ¤æ–­ãŒå¿…è¦",
                ],
                "pnl_pct": pnl_pct,
            })

    # urgency é †ã«ã‚½ãƒ¼ãƒˆ: critical > warning > info
    _urgency_order = {"critical": 0, "warning": 1, "info": 2}
    alerts.sort(key=lambda x: (_urgency_order.get(x["urgency"], 9), x["symbol"]))
    return alerts


def _is_nan(v) -> bool:
    """NaN åˆ¤å®šãƒ˜ãƒ«ãƒ‘ãƒ¼."""
    try:
        import math
        return math.isnan(float(v))
    except (TypeError, ValueError):
        return True
