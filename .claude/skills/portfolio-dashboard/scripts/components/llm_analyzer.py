"""LLM ãƒ™ãƒ¼ã‚¹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æžãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«.

``copilot_client`` ã‚’é€šã˜ã¦ GitHub Copilot CLI ã‚’å‘¼ã³å‡ºã—ã€
çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡žãƒ»ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå½±éŸ¿åˆ†æžã‚’è¡Œã†ã€‚

CLI ã®å®Ÿè¡Œãƒ»ãƒ¢ãƒ‡ãƒ«ç®¡ç†ãƒ»ãƒ­ã‚°è¨˜éŒ²ã¯ ``copilot_client`` ã«å§”è­²ã—ã€
æœ¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹å›ºæœ‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æžãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«é›†ä¸­ã™ã‚‹ã€‚

åˆ©ç”¨æ¡ä»¶:
  - ``copilot`` CLI ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã§ GitHub èªè¨¼æ¸ˆã¿

``copilot`` ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®å ´åˆã¯ ``is_available()`` ãŒ False ã‚’è¿”ã™ãŸã‚ã€
å‘¼ã³å‡ºã—å´ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã€‚
"""

from __future__ import annotations

import hashlib
import json
import logging
import time
from typing import Any

from components.copilot_client import (
    AVAILABLE_MODELS,  # re-export: app.py ã‹ã‚‰ã®å‚ç…§ã‚’ç¶­æŒ
    DEFAULT_MODEL,
    call as copilot_call,
    is_available,      # re-export
)

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
# ---------------------------------------------------------------------------

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åˆ†æžã‚­ãƒ£ãƒƒã‚·ãƒ¥ TTLï¼ˆç§’ï¼‰ã€‚
# ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå¤‰ã‚ã‚‰ãªã‘ã‚Œã° LLM å†åˆ†æžã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ Premium Request ã‚’ç¯€ç´„ã™ã‚‹ã€‚
DEFAULT_CACHE_TTL_SEC: int = 3600  # 1 æ™‚é–“

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ TTL ã® UI é¸æŠžè‚¢: (label, seconds)
CACHE_TTL_OPTIONS: list[tuple[str, int]] = [
    ("1æ™‚é–“", 3600),
    ("3æ™‚é–“", 10800),
    ("6æ™‚é–“", 21600),
    ("12æ™‚é–“", 43200),
    ("24æ™‚é–“", 86400),
]

# ã‚«ãƒ†ã‚´ãƒª â†’ icon / label ã®æ­£è¦ãƒžãƒƒãƒ”ãƒ³ã‚°
_CATEGORY_ICONS: dict[str, dict[str, str]] = {
    "é‡‘åˆ©": {"icon": "ðŸ¦", "label": "é‡‘åˆ©ãƒ»é‡‘èžæ”¿ç­–"},
    "ç‚ºæ›¿": {"icon": "ðŸ’±", "label": "ç‚ºæ›¿"},
    "åœ°æ”¿å­¦": {"icon": "ðŸŒ", "label": "åœ°æ”¿å­¦ãƒ»è²¿æ˜“"},
    "æ™¯æ°—": {"icon": "ðŸ“Š", "label": "æ™¯æ°—ãƒ»çµŒæ¸ˆæŒ‡æ¨™"},
    "ãƒ†ã‚¯ãƒŽãƒ­ã‚¸ãƒ¼": {"icon": "ðŸ’»", "label": "ãƒ†ã‚¯ãƒŽãƒ­ã‚¸ãƒ¼"},
    "ã‚¨ãƒãƒ«ã‚®ãƒ¼": {"icon": "â›½", "label": "ã‚¨ãƒãƒ«ã‚®ãƒ¼"},
}


# ---------------------------------------------------------------------------
# åˆ†æžã‚­ãƒ£ãƒƒã‚·ãƒ¥: ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå¤‰ã‚ã‚‰ãªã‘ã‚Œã° LLM å†å‘¼ã³å‡ºã—ã‚’ã‚¹ã‚­ãƒƒãƒ—
# ---------------------------------------------------------------------------
_analysis_cache: dict[str, Any] = {
    "hash": "",          # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ä¸€è¦§ã® SHA-256
    "results": None,     # å‰å›žã®åˆ†æžçµæžœ
    "timestamp": 0.0,    # å‰å›žåˆ†æžæ™‚åˆ» (time.time())
    "model": "",         # å‰å›žä½¿ç”¨ãƒ¢ãƒ‡ãƒ«
}


def _compute_news_hash(news_items: list[dict]) -> str:
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã®ãƒªã‚¹ãƒˆã‹ã‚‰æ±ºå®šçš„ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆã™ã‚‹."""
    titles = sorted(item.get("title", "") for item in news_items if item.get("title"))
    return hashlib.sha256("\n".join(titles).encode()).hexdigest()


def get_cache_info() -> dict[str, Any]:
    """ç¾åœ¨ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹ã‚’è¿”ã™ï¼ˆUI è¡¨ç¤ºç”¨ï¼‰."""
    ts = _analysis_cache["timestamp"]
    if ts == 0:
        return {"cached": False, "age_sec": 0, "model": ""}
    age = time.time() - ts
    return {
        "cached": True,
        "age_sec": int(age),
        "model": _analysis_cache["model"],
    }


def clear_cache() -> None:
    """åˆ†æžã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å¼·åˆ¶ã‚¯ãƒªã‚¢ã™ã‚‹."""
    _analysis_cache["hash"] = ""
    _analysis_cache["results"] = None
    _analysis_cache["timestamp"] = 0.0
    _analysis_cache["model"] = ""


def analyze_news_batch(
    news_items: list[dict],
    positions: list[dict],
    *,
    model: str | None = None,
    timeout: int = 60,
    cache_ttl: int = DEFAULT_CACHE_TTL_SEC,
) -> list[dict] | None:
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ã‚’ Copilot CLI ã§ãƒãƒƒãƒåˆ†æžã™ã‚‹.

    Parameters
    ----------
    news_items : list[dict]
        ``fetch_economic_news`` ãŒåŽé›†ã—ãŸç”Ÿãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆ.
        å„è¦ç´ ã« ``title``, ``publisher``, ``source_name`` ãŒå«ã¾ã‚Œã‚‹.
    positions : list[dict]
        ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ä¿æœ‰éŠ˜æŸ„ãƒªã‚¹ãƒˆ.
    model : str | None
        ãƒ¢ãƒ‡ãƒ« ID (``copilot --model`` ã®å€¤). çœç•¥æ™‚ã¯ ``_DEFAULT_MODEL``.
    timeout : int
        CLI ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°.
    cache_ttl : int
        åˆ†æžçµæžœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé–“ï¼ˆç§’ï¼‰ã€‚ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒåŒä¸€ã‹ã¤ TTL å†…ãªã‚‰
        LLM ã‚’å†å‘¼ã³å‡ºã—ã›ãšã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¿”ã™ã€‚0 ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹ã€‚

    Returns
    -------
    list[dict] | None
        åˆ†æžçµæžœãƒªã‚¹ãƒˆ. å„è¦ç´ ::

            {
                "id": int,
                "categories": [...],
                "impact_level": str,
                "affected_holdings": [...],
                "reason": str,
            }

        CLI ãŒåˆ©ç”¨ä¸å¯ï¼å¤±æ•—ã—ãŸå ´åˆã¯ ``None`` ã‚’è¿”ã™.
        å‘¼ã³å‡ºã—å´ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ã“ã¨.
    """
    if not is_available():
        return None

    mdl = model or DEFAULT_MODEL

    # --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ ---
    news_hash = _compute_news_hash(news_items)
    if (
        cache_ttl > 0
        and _analysis_cache["results"] is not None
        and _analysis_cache["hash"] == news_hash
        and _analysis_cache["model"] == mdl
        and (time.time() - _analysis_cache["timestamp"]) < cache_ttl
    ):
        age = int(time.time() - _analysis_cache["timestamp"])
        logger.info(
            "[llm_analyzer] cache hit (age=%ds, ttl=%ds) â€” skipping LLM call",
            age, cache_ttl,
        )
        return _analysis_cache["results"]

    # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ¦‚è¦
    pf_summary = _build_portfolio_summary(positions)

    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆ
    news_list: list[dict[str, Any]] = []
    for i, item in enumerate(news_items):
        title = item.get("title", "")
        if not title:
            continue
        news_list.append({
            "id": i,
            "title": title,
            "publisher": item.get("publisher", ""),
            "source": item.get("source_name", ""),
        })

    if not news_list:
        return []

    prompt = _build_analysis_prompt(news_list, pf_summary)

    try:
        raw = copilot_call(
            prompt, model=mdl, timeout=timeout,
            source="news_analysis",
        )
        if raw is None:
            return None
        results = _parse_response(raw, len(news_items))
        # --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–° ---
        if results is not None:
            _analysis_cache["hash"] = news_hash
            _analysis_cache["results"] = results
            _analysis_cache["timestamp"] = time.time()
            _analysis_cache["model"] = mdl
        return results
    except Exception as exc:
        logger.warning("News analysis failed: %s", exc)
        return None


# =====================================================================
# internal helpers
# =====================================================================


def _build_portfolio_summary(positions: list[dict]) -> str:
    """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¦‚è¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ."""
    lines: list[str] = []
    for p in positions:
        sym = p.get("symbol", "")
        sector = p.get("sector", "")
        currency = p.get("currency", "JPY")
        weight = p.get("weight_pct", 0)
        if sector == "Cash" or not sym:
            continue
        lines.append(f"- {sym}: ã‚»ã‚¯ã‚¿ãƒ¼={sector}, é€šè²¨={currency}, æ¯”çŽ‡={weight:.1f}%")
    return "\n".join(lines) if lines else "ï¼ˆä¿æœ‰éŠ˜æŸ„ãªã—ï¼‰"


def _build_analysis_prompt(news_list: list[dict], pf_summary: str) -> str:
    """åˆ†æžç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰."""
    news_text = json.dumps(news_list, ensure_ascii=False, indent=2)

    return f"""ã‚ãªãŸã¯çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æžã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ã‚’ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®è¦³ç‚¹ã‹ã‚‰åˆ†æžã—ã¦ãã ã•ã„ã€‚

## ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä¿æœ‰éŠ˜æŸ„
{pf_summary}

## ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§
{news_text}

## ã‚¿ã‚¹ã‚¯
å„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã¤ã„ã¦ä»¥ä¸‹ã‚’åˆ†æžã—ã€JSONé…åˆ—ã§è¿”ã—ã¦ãã ã•ã„:

1. **categories**: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å½±éŸ¿ã‚«ãƒ†ã‚´ãƒªï¼ˆè¤‡æ•°å¯ï¼‰ã€‚ä»¥ä¸‹ã‹ã‚‰é¸æŠž:
   - é‡‘åˆ©: é‡‘åˆ©ãƒ»ä¸­å¤®éŠ€è¡Œãƒ»é‡‘èžæ”¿ç­–é–¢é€£
   - ç‚ºæ›¿: ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆãƒ»é€šè²¨é–¢é€£
   - åœ°æ”¿å­¦: åœ°æ”¿å­¦ãƒªã‚¹ã‚¯ãƒ»è²¿æ˜“æ‘©æ“¦ãƒ»åˆ¶è£é–¢é€£
   - æ™¯æ°—: æ™¯æ°—å‹•å‘ãƒ»çµŒæ¸ˆæŒ‡æ¨™ãƒ»é›‡ç”¨é–¢é€£
   - ãƒ†ã‚¯ãƒŽãƒ­ã‚¸ãƒ¼: ãƒ†ãƒƒã‚¯æ¥­ç•Œãƒ»AIãƒ»åŠå°Žä½“é–¢é€£
   - ã‚¨ãƒãƒ«ã‚®ãƒ¼: åŽŸæ²¹ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼é–¢é€£

2. **impact_level**: ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¸ã®å½±éŸ¿åº¦ï¼ˆ"high"/"medium"/"low"/"none"ï¼‰
   - high: ä¿æœ‰éŠ˜æŸ„ã®å¤šãã«ç›´æŽ¥å½±éŸ¿ãŒã‚ã‚‹é‡å¤§ãƒ‹ãƒ¥ãƒ¼ã‚¹
   - medium: ä¸€éƒ¨ã®ä¿æœ‰éŠ˜æŸ„ã‚„ã‚»ã‚¯ã‚¿ãƒ¼ã«å½±éŸ¿
   - low: é–“æŽ¥çš„ãªå½±éŸ¿ã®å¯èƒ½æ€§
   - none: ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¸ã®å½±éŸ¿ãªã—

3. **affected_holdings**: å½±éŸ¿ã‚’å—ã‘ã‚‹ä¿æœ‰éŠ˜æŸ„ã®ã‚·ãƒ³ãƒœãƒ«ãƒªã‚¹ãƒˆ

4. **reason**: å½±éŸ¿ã®ç†ç”±ï¼ˆæ—¥æœ¬èªžã€50æ–‡å­—ä»¥å†…ï¼‰

## å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®JSONé…åˆ—ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜Žæ–‡ã¯ä¸è¦ã§ã™:
```json
[
  {{"id": 0, "categories": ["é‡‘åˆ©"], "impact_level": "medium", "affected_holdings": ["7203.T"], "reason": "æ—¥éŠ€ã®åˆ©ä¸Šã’ã§è‡ªå‹•è»Šãƒ­ãƒ¼ãƒ³é‡‘åˆ©ã«å½±éŸ¿"}}
]
```

categoriesã¯æ–‡å­—åˆ—ã®é…åˆ—ã§ã€ã‚«ãƒ†ã‚´ãƒªåã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ï¼ˆicon/labelã¯å‘¼ã³å‡ºã—å´ã§ä»˜ä¸Žã—ã¾ã™ï¼‰ã€‚"""


def _parse_response(raw_text: str, expected_count: int) -> list[dict] | None:
    """Copilot CLI å¿œç­”ã‹ã‚‰ JSON é…åˆ—ã‚’æŠ½å‡ºãƒ»ãƒ‘ãƒ¼ã‚¹ã™ã‚‹."""
    text = raw_text.strip()

    # ```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
    if "```json" in text:
        start = text.index("```json") + 7
        end = text.index("```", start)
        text = text[start:end].strip()
    elif "```" in text:
        start = text.index("```") + 3
        end = text.index("```", start)
        text = text[start:end].strip()

    # [ ã§å§‹ã¾ã‚‹ JSON ã‚’æŽ¢ã™
    if not text.startswith("["):
        idx = text.find("[")
        if idx >= 0:
            text = text[idx:]
        else:
            return None

    # æœ«å°¾ã® ] ã¾ã§
    last_bracket = text.rfind("]")
    if last_bracket >= 0:
        text = text[: last_bracket + 1]

    try:
        parsed = json.loads(text)
    except json.JSONDecodeError:
        logger.warning("Failed to parse Copilot CLI JSON response")
        return None

    if not isinstance(parsed, list):
        return None

    # å„ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ­£è¦åŒ–
    results: list[dict] = []
    for item in parsed:
        if not isinstance(item, dict):
            continue

        # categories: æ–‡å­—åˆ—ãƒªã‚¹ãƒˆ â†’ dict ãƒªã‚¹ãƒˆã«å¤‰æ›
        raw_cats = item.get("categories", [])
        categories: list[dict] = []
        for cat in raw_cats:
            if isinstance(cat, str):
                cat_name = cat
            elif isinstance(cat, dict):
                cat_name = cat.get("category", "")
            else:
                continue
            if cat_name in _CATEGORY_ICONS:
                categories.append({
                    "category": cat_name,
                    **_CATEGORY_ICONS[cat_name],
                })

        results.append({
            "id": item.get("id", len(results)),
            "categories": categories,
            "impact_level": item.get("impact_level", "none"),
            "affected_holdings": item.get("affected_holdings", []),
            "reason": item.get("reason", ""),
        })

    return results


# =====================================================================
# ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µãƒžãƒªãƒ¼ç”Ÿæˆ
# =====================================================================

# ã‚µãƒžãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ â€” ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå¤‰ã‚ã‚‰ãªã‘ã‚Œã°å†ç”Ÿæˆã—ãªã„
_summary_cache: dict[str, Any] = {
    "hash": "",
    "result": None,
    "timestamp": 0.0,
    "model": "",
}


def get_summary_cache_info() -> dict[str, Any]:
    """ã‚µãƒžãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®çŠ¶æ…‹ã‚’è¿”ã™."""
    ts = _summary_cache["timestamp"]
    if ts == 0:
        return {"cached": False, "age_sec": 0, "model": ""}
    age = time.time() - ts
    return {"cached": True, "age_sec": int(age), "model": _summary_cache["model"]}


def clear_summary_cache() -> None:
    """ã‚µãƒžãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å¼·åˆ¶ã‚¯ãƒªã‚¢ã™ã‚‹."""
    _summary_cache["hash"] = ""
    _summary_cache["result"] = None
    _summary_cache["timestamp"] = 0.0
    _summary_cache["model"] = ""


def generate_news_summary(
    news_items: list[dict],
    positions: list[dict],
    *,
    model: str | None = None,
    timeout: int = 60,
    cache_ttl: int = DEFAULT_CACHE_TTL_SEC,
) -> dict | None:
    """LLM åˆ†æžæ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰ã‚µãƒžãƒªãƒ¼ã‚’ç”Ÿæˆã™ã‚‹.

    Parameters
    ----------
    news_items : list[dict]
        ``fetch_economic_news`` ãŒè¿”ã—ãŸåˆ†æžæ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆ.
        ``analysis_method == "llm"`` ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å‰æ.
    positions : list[dict]
        ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä¿æœ‰éŠ˜æŸ„ãƒªã‚¹ãƒˆ.
    model : str | None
        ãƒ¢ãƒ‡ãƒ« ID. çœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«.
    timeout : int
        CLI ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°.
    cache_ttl : int
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé–“ï¼ˆç§’ï¼‰.

    Returns
    -------
    dict | None
        ã‚µãƒžãƒªãƒ¼çµæžœ::

            {
                "overview": str,          # å…¨ä½“æ¦‚è¦ï¼ˆ2-3æ–‡ï¼‰
                "key_points": [           # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒã‚¤ãƒ³ãƒˆ
                    {
                        "category": str,  # ã‚«ãƒ†ã‚´ãƒªå
                        "icon": str,      # ã‚¢ã‚¤ã‚³ãƒ³
                        "summary": str,   # è¦ç‚¹
                        "news_ids": [int],# é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹IDï¼ˆãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ï¼‰
                    },
                ],
                "portfolio_alert": str,   # PFã¸ã®æ³¨æ„ç‚¹ï¼ˆã‚ã‚Œã°ï¼‰
            }

        å¤±æ•—æ™‚ã¯ ``None``.
    """
    if not is_available():
        return None

    mdl = model or DEFAULT_MODEL

    # --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ ---
    news_hash = _compute_news_hash(news_items)
    if (
        cache_ttl > 0
        and _summary_cache["result"] is not None
        and _summary_cache["hash"] == news_hash
        and _summary_cache["model"] == mdl
        and (time.time() - _summary_cache["timestamp"]) < cache_ttl
    ):
        logger.info("[llm_analyzer] summary cache hit â€” skipping LLM call")
        return _summary_cache["result"]

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    prompt = _build_summary_prompt(news_items, positions)

    try:
        raw = copilot_call(
            prompt, model=mdl, timeout=timeout,
            source="news_summary",
        )
        if raw is None:
            return None
        result = _parse_summary_response(raw)
        if result is not None:
            _summary_cache["hash"] = news_hash
            _summary_cache["result"] = result
            _summary_cache["timestamp"] = time.time()
            _summary_cache["model"] = mdl
        return result
    except Exception as exc:
        logger.warning("News summary generation failed: %s", exc)
        return None


def _build_summary_prompt(news_items: list[dict], positions: list[dict]) -> str:
    """ã‚µãƒžãƒªãƒ¼ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹."""
    pf_summary = _build_portfolio_summary(positions)

    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ã¾ã¨ã‚ã‚‹
    news_lines: list[str] = []
    for i, item in enumerate(news_items):
        title = item.get("title", "")
        if not title:
            continue
        impact = item.get("portfolio_impact", {}).get("impact_level", "none")
        cats = ", ".join(
            c.get("category", "") if isinstance(c, dict) else str(c)
            for c in item.get("categories", [])
        )
        reason = item.get("portfolio_impact", {}).get("reason", "")
        news_lines.append(f"[{i}] {title} | å½±éŸ¿={impact} | åˆ†é‡Ž={cats} | ç†ç”±={reason}")

    news_text = "\n".join(news_lines)

    return f"""ã‚ãªãŸã¯çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®åˆ†æžæ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’èª­ã¿ã€æŠ•è³‡å®¶å‘ã‘ã®ç°¡æ½”ãªã‚µãƒžãƒªãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä¿æœ‰éŠ˜æŸ„
{pf_summary}

## åˆ†æžæ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§
ï¼ˆå„è¡Œ: [ID] ã‚¿ã‚¤ãƒˆãƒ« | å½±éŸ¿åº¦ | åˆ†é‡Ž | ç†ç”±ï¼‰
{news_text}

## ã‚¿ã‚¹ã‚¯
ä»¥ä¸‹ã®JSONå½¢å¼ã§ã‚µãƒžãƒªãƒ¼ã‚’è¿”ã—ã¦ãã ã•ã„:

```json
{{
  "overview": "å…¨ä½“æ¦‚è¦ã‚’2-3æ–‡ã§ã€‚ä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å…¨ä½“çš„ãªãƒˆãƒ¼ãƒ³ï¼ˆãƒªã‚¹ã‚¯ã‚ªãƒ³/ã‚ªãƒ•ã€æ³¨ç›®ãƒ†ãƒ¼ãƒžç­‰ï¼‰ã‚’è¿°ã¹ã‚‹",
  "key_points": [
    {{
      "category": "ã‚«ãƒ†ã‚´ãƒªåï¼ˆé‡‘åˆ©/ç‚ºæ›¿/åœ°æ”¿å­¦/æ™¯æ°—/ãƒ†ã‚¯ãƒŽãƒ­ã‚¸ãƒ¼/ã‚¨ãƒãƒ«ã‚®ãƒ¼ ã®ã„ãšã‚Œã‹ï¼‰",
      "summary": "ãã®ã‚«ãƒ†ã‚´ãƒªã«é–¢ã™ã‚‹è¦ç‚¹ã‚’1-2æ–‡ã§ã€‚å…·ä½“çš„ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã«è¨€åŠã™ã‚‹",
      "news_ids": [0, 1]
    }}
  ],
  "portfolio_alert": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¸ã®æ³¨æ„ç‚¹ã‚’1-2æ–‡ã§ã€‚å½±éŸ¿åº¦ãŒé«˜ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚Œã°ãã®è¦ç´„ã€‚ãªã‘ã‚Œã°ç©ºæ–‡å­—"
}}
```

## åˆ¶ç´„
- key_points ã¯å®Ÿéš›ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚‹ã‚«ãƒ†ã‚´ãƒªã®ã¿ã€‚æœ€å¤§4ã‚«ãƒ†ã‚´ãƒª
- news_ids ã¯ãã®ã‚«ãƒ†ã‚´ãƒªã«é–¢é€£ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®[ID]ç•ªå·
- overview, summary, portfolio_alert ã¯æ—¥æœ¬èªžã§è¨˜è¿°
- JSONã®ã¿ã‚’è¿”ã™ã“ã¨ã€‚èª¬æ˜Žæ–‡ã¯ä¸è¦"""


def _parse_summary_response(raw_text: str) -> dict | None:
    """ã‚µãƒžãƒªãƒ¼å¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹."""
    text = raw_text.strip()

    # ```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
    if "```json" in text:
        start = text.index("```json") + 7
        end = text.index("```", start)
        text = text[start:end].strip()
    elif "```" in text:
        start = text.index("```") + 3
        end = text.index("```", start)
        text = text[start:end].strip()

    # { ã§å§‹ã¾ã‚‹ JSON ã‚’æŽ¢ã™ï¼ˆé…åˆ— [ ã¯æ‹’å¦ï¼‰
    if text.startswith("["):
        return None
    if not text.startswith("{"):
        idx = text.find("{")
        if idx >= 0:
            text = text[idx:]
        else:
            return None

    # æœ«å°¾ã® } ã¾ã§
    last_brace = text.rfind("}")
    if last_brace >= 0:
        text = text[: last_brace + 1]

    try:
        parsed = json.loads(text)
    except json.JSONDecodeError:
        logger.warning("Failed to parse summary JSON response")
        return None

    if not isinstance(parsed, dict):
        return None

    overview = parsed.get("overview", "")
    portfolio_alert = parsed.get("portfolio_alert", "")
    raw_points = parsed.get("key_points", [])

    key_points: list[dict] = []
    for pt in raw_points:
        if not isinstance(pt, dict):
            continue
        cat_name = pt.get("category", "")
        cat_info = _CATEGORY_ICONS.get(cat_name, {})
        key_points.append({
            "category": cat_name,
            "icon": cat_info.get("icon", "ðŸ“Œ"),
            "label": cat_info.get("label", cat_name),
            "summary": pt.get("summary", ""),
            "news_ids": pt.get("news_ids", []),
        })

    return {
        "overview": overview,
        "key_points": key_points,
        "portfolio_alert": portfolio_alert,
    }


# =====================================================================
# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚µãƒžãƒªãƒ¼ç”Ÿæˆ
# =====================================================================

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚µãƒžãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_health_summary_cache: dict[str, Any] = {
    "hash": "",
    "result": None,
    "timestamp": 0.0,
    "model": "",
}


def get_health_summary_cache_info() -> dict[str, Any]:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚µãƒžãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®çŠ¶æ…‹ã‚’è¿”ã™."""
    ts = _health_summary_cache["timestamp"]
    if ts == 0:
        return {"cached": False, "age_sec": 0, "model": ""}
    age = time.time() - ts
    return {"cached": True, "age_sec": int(age), "model": _health_summary_cache["model"]}


def clear_health_summary_cache() -> None:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚µãƒžãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å¼·åˆ¶ã‚¯ãƒªã‚¢ã™ã‚‹."""
    _health_summary_cache["hash"] = ""
    _health_summary_cache["result"] = None
    _health_summary_cache["timestamp"] = 0.0
    _health_summary_cache["model"] = ""


def _compute_health_hash(health_data: dict, news_items: list[dict] | None = None) -> str:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆã™ã‚‹."""
    positions = health_data.get("positions", [])
    parts = []
    for p in positions:
        parts.append(f"{p.get('symbol', '')}:{p.get('alert_level', '')}:{p.get('pnl_pct', 0)}")
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã‚‚ãƒãƒƒã‚·ãƒ¥ã«å«ã‚ã‚‹ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå¤‰ã‚ã‚Œã°å†åˆ†æžï¼‰
    if news_items:
        for n in news_items:
            title = n.get("title", "")
            if title:
                parts.append(f"news:{title}")
    return hashlib.sha256("\n".join(sorted(parts)).encode()).hexdigest()


def generate_health_summary(
    health_data: dict,
    *,
    news_items: list[dict] | None = None,
    model: str | None = None,
    timeout: int = 60,
    cache_ttl: int = DEFAULT_CACHE_TTL_SEC,
) -> dict | None:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæžœï¼‹é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‹ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰LLMã‚µãƒžãƒªãƒ¼ã‚’ç”Ÿæˆã™ã‚‹.

    Parameters
    ----------
    health_data : dict
        ``run_dashboard_health_check()`` ãŒè¿”ã™ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæžœ.
        å„ position ã«ã¯ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆPER, PBR, ROE ç­‰ï¼‰ãŒå«ã¾ã‚Œã‚‹.
    news_items : list[dict] | None
        çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆ. PFå½±éŸ¿ã®ã‚ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã¿ã‚’æ¸¡ã™ã“ã¨ã‚’æŽ¨å¥¨.
    model : str | None
        ãƒ¢ãƒ‡ãƒ« ID. çœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«.
    timeout : int
        CLI ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°.
    cache_ttl : int
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé–“ï¼ˆç§’ï¼‰.

    Returns
    -------
    dict | None
        ã‚µãƒžãƒªãƒ¼çµæžœ::

            {
                "overview": str,             # å…¨ä½“æ¦‚è¦ï¼ˆ2-3æ–‡ï¼‰
                "stock_assessments": [        # éŠ˜æŸ„åˆ¥è©•ä¾¡
                    {
                        "symbol": str,
                        "name": str,
                        "assessment": str,   # 1-2æ–‡ã®è©•ä¾¡
                        "action": str,       # æŽ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
                    },
                ],
                "risk_warning": str,         # ãƒªã‚¹ã‚¯è­¦å‘Šï¼ˆã‚ã‚Œã°ï¼‰
            }

        å¤±æ•—æ™‚ã¯ ``None``.
    """
    if not is_available():
        return None

    mdl = model or DEFAULT_MODEL

    # --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ ---
    health_hash = _compute_health_hash(health_data, news_items)
    if (
        cache_ttl > 0
        and _health_summary_cache["result"] is not None
        and _health_summary_cache["hash"] == health_hash
        and _health_summary_cache["model"] == mdl
        and (time.time() - _health_summary_cache["timestamp"]) < cache_ttl
    ):
        logger.info("[llm_analyzer] health summary cache hit â€” skipping LLM call")
        return _health_summary_cache["result"]

    prompt = _build_health_summary_prompt(health_data, news_items=news_items)

    try:
        raw = copilot_call(
            prompt, model=mdl, timeout=timeout,
            source="health_summary",
        )
        if raw is None:
            return None
        result = _parse_health_summary_response(raw)
        if result is not None:
            _health_summary_cache["hash"] = health_hash
            _health_summary_cache["result"] = result
            _health_summary_cache["timestamp"] = time.time()
            _health_summary_cache["model"] = mdl
        return result
    except Exception as exc:
        logger.warning("Health summary generation failed: %s", exc)
        return None


def _build_health_summary_prompt(
    health_data: dict,
    *,
    news_items: list[dict] | None = None,
) -> str:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚µãƒžãƒªãƒ¼ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹.

    ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæžœãƒ»ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ»é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’çµ±åˆã—ã¦
    LLM ã«æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    summary = health_data.get("summary", {})
    positions = health_data.get("positions", [])
    sell_alerts = health_data.get("sell_alerts", [])

    # ãƒã‚¸ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ã¾ã¨ã‚ã‚‹ï¼ˆãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæžœ + ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ï¼‰
    pos_lines: list[str] = []
    for p in positions:
        symbol = p.get("symbol", "")
        name = p.get("name", symbol)
        alert = p.get("alert_level", "none")
        trend = p.get("trend", "ä¸æ˜Ž")
        rsi = p.get("rsi", 0)
        pnl = p.get("pnl_pct", 0)
        reasons = " / ".join(p.get("alert_reasons", [])) if p.get("alert_reasons") else "-"
        trap = "ãƒãƒªãƒ¥ãƒ¼ãƒˆãƒ©ãƒƒãƒ—" if p.get("value_trap") else ""
        cross = p.get("cross_signal", "none")
        cross_str = ""
        if cross == "golden_cross":
            cross_str = f"GC({p.get('days_since_cross', '?')}æ—¥å‰)"
        elif cross == "death_cross":
            cross_str = f"DC({p.get('days_since_cross', '?')}æ—¥å‰)"
        quality = p.get("change_quality", "")
        stability = p.get("return_stability", "")

        extras = " / ".join(filter(None, [trap, cross_str, quality, stability]))

        # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿
        fund_parts: list[str] = []
        per = p.get("per")
        if per is not None:
            fund_parts.append(f"PER={per:.1f}")
        pbr = p.get("pbr")
        if pbr is not None:
            fund_parts.append(f"PBR={pbr:.2f}")
        roe = p.get("roe")
        if roe is not None:
            fund_parts.append(f"ROE={roe * 100:.1f}%")
        rev_g = p.get("revenue_growth")
        if rev_g is not None:
            fund_parts.append(f"å£²ä¸Šæˆé•·={rev_g * 100:+.1f}%")
        earn_g = p.get("earnings_growth")
        if earn_g is not None:
            fund_parts.append(f"åˆ©ç›Šæˆé•·={earn_g * 100:+.1f}%")
        div_y = p.get("dividend_yield")
        if div_y is not None:
            fund_parts.append(f"é…å½“={div_y * 100:.2f}%")
        fwd_eps = p.get("forward_eps")
        trail_eps = p.get("trailing_eps")
        if fwd_eps is not None and trail_eps is not None:
            if trail_eps != 0:
                eps_chg = ((fwd_eps / trail_eps) - 1) * 100
                fund_parts.append(f"EPSæ–¹å‘={eps_chg:+.1f}%")
        sector = p.get("sector", "")
        industry = p.get("industry", "")

        fund_str = ", ".join(fund_parts) if fund_parts else ""
        sector_str = f"{sector}/{industry}" if sector else ""

        line = (
            f"- {name}({symbol}): åˆ¤å®š={alert}, ãƒˆãƒ¬ãƒ³ãƒ‰={trend}, "
            f"RSI={rsi:.1f}, æç›Š={pnl:+.1f}%, ç†ç”±={reasons}"
        )
        if extras:
            line += f", è£œè¶³={extras}"
        if sector_str:
            line += f", ã‚»ã‚¯ã‚¿ãƒ¼={sector_str}"
        if fund_str:
            line += f", ãƒ•ã‚¡ãƒ³ãƒ€=[{fund_str}]"
        pos_lines.append(line)

    pos_text = "\n".join(pos_lines) if pos_lines else "ï¼ˆä¿æœ‰éŠ˜æŸ„ãªã—ï¼‰"

    # å£²ã‚Šã‚¢ãƒ©ãƒ¼ãƒˆæƒ…å ±
    alert_lines: list[str] = []
    for a in sell_alerts:
        alert_lines.append(
            f"- {a.get('name', '')}({a.get('symbol', '')}): "
            f"ç·Šæ€¥åº¦={a.get('urgency', '')}, ã‚¢ã‚¯ã‚·ãƒ§ãƒ³={a.get('action', '')}, "
            f"ç†ç”±={a.get('reason', '')}"
        )
    alert_text = "\n".join(alert_lines) if alert_lines else "ï¼ˆãªã—ï¼‰"

    # é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±
    news_section = ""
    if news_items:
        # PFå½±éŸ¿ãŒã‚ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å„ªå…ˆçš„ã«å«ã‚ã‚‹
        impact_news = [
            n for n in news_items
            if n.get("portfolio_impact", {}).get("impact_level", "none") != "none"
        ]
        # å½±éŸ¿ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå°‘ãªã‘ã‚Œã°ã€ãã®ä»–ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚‚å°‘ã—å«ã‚ã‚‹
        other_news = [
            n for n in news_items
            if n.get("portfolio_impact", {}).get("impact_level", "none") == "none"
        ]

        news_lines: list[str] = []
        for n in impact_news[:10]:
            impact = n.get("portfolio_impact", {})
            affected = ", ".join(impact.get("affected_holdings", []))
            reason = impact.get("reason", "")
            level = impact.get("impact_level", "none")
            news_lines.append(
                f"- [{level}] {n.get('title', '')}"
                + (f" â†’ å½±éŸ¿éŠ˜æŸ„: {affected}" if affected else "")
                + (f" ({reason})" if reason else "")
            )
        for n in other_news[:5]:
            news_lines.append(f"- [å‚è€ƒ] {n.get('title', '')}")

        if news_lines:
            news_text = "\n".join(news_lines)
            news_section = f"""
## é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆçµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ & PFå½±éŸ¿ï¼‰
{news_text}
"""

    return f"""ã‚ãªãŸã¯ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯åˆ†æžã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæžœã€ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ã€é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ç·åˆçš„ã«èª­ã¿ã€æŠ•è³‡å®¶å‘ã‘ã®ç°¡æ½”ãªã‚µãƒžãƒªãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ã‚µãƒžãƒªãƒ¼çµ±è¨ˆ
- åˆè¨ˆ: {summary.get('total', 0)}éŠ˜æŸ„
- å¥å…¨: {summary.get('healthy', 0)}, æ—©æœŸè­¦å‘Š: {summary.get('early_warning', 0)}, æ³¨æ„: {summary.get('caution', 0)}, æ’¤é€€: {summary.get('exit', 0)}

## å„éŠ˜æŸ„ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæžœ & ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿
{pos_text}

## å£²ã‚Šã‚¿ã‚¤ãƒŸãƒ³ã‚°é€šçŸ¥
{alert_text}
{news_section}
## ã‚¿ã‚¹ã‚¯
ä»¥ä¸‹ã®JSONå½¢å¼ã§ã‚µãƒžãƒªãƒ¼ã‚’è¿”ã—ã¦ãã ã•ã„:

```json
{{
  "overview": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“ã®å¥å…¨æ€§ã‚’2-3æ–‡ã§è©•ä¾¡ã€‚ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«é¢ãƒ»ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«é¢ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®3è¦³ç‚¹ã‹ã‚‰ç·åˆåˆ¤æ–­ã™ã‚‹",
  "stock_assessments": [
    {{
      "symbol": "éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«",
      "name": "éŠ˜æŸ„å",
      "assessment": "ã“ã®éŠ˜æŸ„ã®ç¾çŠ¶ã‚’1-2æ–‡ã§è©•ä¾¡ï¼ˆãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæžœã€ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¸ã¾ãˆã¦ï¼‰",
      "action": "æŽ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆä¿æœ‰ç¶™ç¶š/ä¸€éƒ¨åˆ©ç¢º/æåˆ‡ã‚Šæ¤œè¨Ž/æ³¨è¦– ç­‰ï¼‰"
    }}
  ],
  "risk_warning": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“ã®ãƒªã‚¹ã‚¯ã«é–¢ã™ã‚‹æ³¨æ„ç‚¹ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ãƒªã‚¹ã‚¯ã‚‚å«ã‚€ï¼‰ã€‚ãªã‘ã‚Œã°ç©ºæ–‡å­—"
}}
```

## åˆ¶ç´„
- stock_assessments ã¯ã‚¢ãƒ©ãƒ¼ãƒˆãŒã‚ã‚‹éŠ˜æŸ„ï¼ˆalert_level ãŒ none ä»¥å¤–ï¼‰ã®ã¿ã€‚å¥å…¨ãªéŠ˜æŸ„ã¯çœç•¥
- ã‚¢ãƒ©ãƒ¼ãƒˆéŠ˜æŸ„ãŒãªã‘ã‚Œã° stock_assessments ã¯ç©ºé…åˆ—
- ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆPER, ROE, æˆé•·çŽ‡ç­‰ï¼‰ãŒã‚ã‚‹å ´åˆã¯ã€ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³é¢ã®è©•ä¾¡ã‚‚å«ã‚ã‚‹
- é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚‹å ´åˆã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«ä¸Žãˆã‚‹å½±éŸ¿ã‚‚ overview ã‚„ risk_warning ã«åæ˜ ã™ã‚‹
- overview, assessment, risk_warning ã¯æ—¥æœ¬èªžã§ç°¡æ½”ã«
- JSONã®ã¿ã‚’è¿”ã™ã“ã¨ã€‚èª¬æ˜Žæ–‡ã¯ä¸è¦"""


def _parse_health_summary_response(raw_text: str) -> dict | None:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚µãƒžãƒªãƒ¼å¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹."""
    text = raw_text.strip()

    # ```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
    if "```json" in text:
        start = text.index("```json") + 7
        end = text.index("```", start)
        text = text[start:end].strip()
    elif "```" in text:
        start = text.index("```") + 3
        end = text.index("```", start)
        text = text[start:end].strip()

    # { ã§å§‹ã¾ã‚‹ JSON ã‚’æŽ¢ã™ï¼ˆé…åˆ— [ ã¯æ‹’å¦ï¼‰
    if text.startswith("["):
        return None
    if not text.startswith("{"):
        idx = text.find("{")
        if idx >= 0:
            text = text[idx:]
        else:
            return None

    # æœ«å°¾ã® } ã¾ã§
    last_brace = text.rfind("}")
    if last_brace >= 0:
        text = text[: last_brace + 1]

    try:
        parsed = json.loads(text)
    except json.JSONDecodeError:
        logger.warning("Failed to parse health summary JSON response")
        return None

    if not isinstance(parsed, dict):
        return None

    overview = parsed.get("overview", "")
    risk_warning = parsed.get("risk_warning", "")
    raw_assessments = parsed.get("stock_assessments", [])

    stock_assessments: list[dict] = []
    for sa in raw_assessments:
        if not isinstance(sa, dict):
            continue
        stock_assessments.append({
            "symbol": sa.get("symbol", ""),
            "name": sa.get("name", ""),
            "assessment": sa.get("assessment", ""),
            "action": sa.get("action", ""),
        })

    return {
        "overview": overview,
        "stock_assessments": stock_assessments,
        "risk_warning": risk_warning,
    }
